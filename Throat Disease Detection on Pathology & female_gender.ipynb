{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b66bf280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de3e2d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad22bf2",
   "metadata": {},
   "source": [
    "## Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3758ffdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recording Id</th>\n",
       "      <th>Type</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diagnosis Notes</th>\n",
       "      <th>Pathology</th>\n",
       "      <th>Audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>w</td>\n",
       "      <td>20</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>w</td>\n",
       "      <td>22</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>n</td>\n",
       "      <td>w</td>\n",
       "      <td>23</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>3-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>n</td>\n",
       "      <td>w</td>\n",
       "      <td>20</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>6-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>n</td>\n",
       "      <td>w</td>\n",
       "      <td>19</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>7-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27</td>\n",
       "      <td>n</td>\n",
       "      <td>w</td>\n",
       "      <td>20</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>27-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>n</td>\n",
       "      <td>w</td>\n",
       "      <td>19</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>17-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>n</td>\n",
       "      <td>w</td>\n",
       "      <td>19</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>8-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>n</td>\n",
       "      <td>w</td>\n",
       "      <td>22</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>10-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2200</td>\n",
       "      <td>n</td>\n",
       "      <td>w</td>\n",
       "      <td>26</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2200-a_n.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Recording Id Type Gender  Age Diagnosis Notes Pathology         Audio\n",
       "0              1    n      w   20          Normal    Normal     1-a_n.wav\n",
       "1              2    n      w   22          Normal    Normal     2-a_n.wav\n",
       "2              3    n      w   23          Normal    Normal     3-a_n.wav\n",
       "5              6    n      w   20          Normal    Normal     6-a_n.wav\n",
       "6              7    n      w   19          Normal    Normal     7-a_n.wav\n",
       "7             27    n      w   20          Normal    Normal    27-a_n.wav\n",
       "8             17    n      w   19          Normal    Normal    17-a_n.wav\n",
       "9              8    n      w   19          Normal    Normal     8-a_n.wav\n",
       "11            10    n      w   22          Normal    Normal    10-a_n.wav\n",
       "12          2200    n      w   26          Normal    Normal  2200-a_n.wav"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1=pd.read_excel('Healthy_data.xlsx')\n",
    "df2=pd.read_excel('Pathological_data.xlsx')\n",
    "df=pd.concat([df1,df2], ignore_index=True)\n",
    "df=df[df.Gender=='w']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5fe054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76cfc7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 929 entries, 0 to 1489\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Recording Id     929 non-null    int64 \n",
      " 1   Type             929 non-null    object\n",
      " 2   Gender           929 non-null    object\n",
      " 3   Age              929 non-null    int64 \n",
      " 4   Diagnosis Notes  866 non-null    object\n",
      " 5   Pathology        929 non-null    object\n",
      " 6   Audio            929 non-null    object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 58.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db9c1b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Audio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <th>w</th>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <th>w</th>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Audio\n",
       "Type Gender       \n",
       "n    w         428\n",
       "p    w         501"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_gender_count = df.groupby([\"Type\",\"Gender\"])[['Audio']].count()\n",
    "type_gender_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d9f69cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Type,Gender'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type_gender_count.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98636eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=df[\"Pathology\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59c7019",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff680d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting MFCC's for every audio file\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "audio_dataset_path = 'Filtered_Audio_Dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa9d6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extraction(file):\n",
    "    audio, sample_rate = librosa.load(file_name) \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr= sample_rate, n_mfcc=80) \n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "722e8c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "929it [00:19, 48.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(df.iterrows()):\n",
    "    file_name = audio_dataset_path+row[\"Audio\"]\n",
    "    final_class_labels = row[\"Pathology\"]\n",
    "    data = features_extraction(file_name)\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c814f35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-261.49933, 114.805534, -72.840965, -0.931277...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-202.87245, 145.96022, -68.10183, -11.444383,...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-167.76535, 133.49133, -77.94643, -9.826728, ...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-205.02122, 137.12006, -66.55497, -12.496069,...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-217.24478, 145.07858, -100.58555, 2.7787614,...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-227.11813, 127.75929, -63.862732, -13.961372...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[-196.28305, 113.32672, -99.92175, 1.0585632, ...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[-207.56131, 135.24808, -61.779488, -17.637135...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-201.10626, 158.06732, -36.131306, 1.6452157,...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[-277.55927, 161.18881, -30.51163, -16.397873,...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature   class\n",
       "0  [-261.49933, 114.805534, -72.840965, -0.931277...  Normal\n",
       "1  [-202.87245, 145.96022, -68.10183, -11.444383,...  Normal\n",
       "2  [-167.76535, 133.49133, -77.94643, -9.826728, ...  Normal\n",
       "3  [-205.02122, 137.12006, -66.55497, -12.496069,...  Normal\n",
       "4  [-217.24478, 145.07858, -100.58555, 2.7787614,...  Normal\n",
       "5  [-227.11813, 127.75929, -63.862732, -13.961372...  Normal\n",
       "6  [-196.28305, 113.32672, -99.92175, 1.0585632, ...  Normal\n",
       "7  [-207.56131, 135.24808, -61.779488, -17.637135...  Normal\n",
       "8  [-201.10626, 158.06732, -36.131306, 1.6452157,...  Normal\n",
       "9  [-277.55927, 161.18881, -30.51163, -16.397873,...  Normal"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df = pd.DataFrame(extracted_features, columns=['feature','class'])\n",
    "extracted_features_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2827c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bb09498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.61499329e+02,  1.14805534e+02, -7.28409653e+01, -9.31277871e-01,\n",
       "       -6.87778549e+01, -2.90463376e+00,  4.69877529e+00,  7.56695986e+00,\n",
       "       -3.33707962e+01,  1.76828156e+01, -4.03612089e+00, -1.42697287e+01,\n",
       "        9.20465565e+00, -2.80942898e+01, -1.00394077e+01, -1.63144569e+01,\n",
       "       -9.73753095e-01, -4.31138134e+00, -9.75323021e-01, -1.19480648e+01,\n",
       "        4.30604649e+00, -9.05258274e+00,  8.25730264e-02,  4.08039131e+01,\n",
       "        2.39141750e+01,  6.14854851e+01,  3.20326614e+01,  8.02177048e+00,\n",
       "       -2.74810147e+00, -9.03449821e+00,  4.29856348e+00, -1.17523634e+00,\n",
       "        1.33330641e+01, -6.40946245e+00, -1.52622843e+01, -5.44703770e+00,\n",
       "        1.03529129e+01, -3.11023307e+00, -8.39600277e+00, -7.93014669e+00,\n",
       "       -5.57793570e+00,  1.33628864e+01, -4.67780113e+00, -1.73656483e+01,\n",
       "       -1.20797033e+01,  3.30997729e+00, -6.23456812e+00,  1.79914856e+00,\n",
       "        1.81635227e+01,  3.11546078e+01,  3.39731293e+01,  2.36189723e+00,\n",
       "        3.56650442e-01,  1.27379984e-01,  1.96595967e+00, -3.74437380e+00,\n",
       "        3.04778504e+00,  1.17016163e+01, -5.68205357e+00, -1.47768602e+01,\n",
       "       -3.44011617e+00,  1.26787863e+01, -4.54433060e+00, -2.59958076e+00,\n",
       "        4.01505619e-01, -2.27284694e+00, -1.98904479e+00, -1.24807763e+00,\n",
       "        6.69117212e+00, -1.67640018e+01, -8.95553780e+00,  8.15494537e+00,\n",
       "        3.47363853e+00,  7.22138739e+00,  7.14855003e+00,  5.03738308e+00,\n",
       "       -2.05320191e+00,  6.38020706e+00,  3.56900358e+00, -1.01759024e+01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df[\"feature\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85fff3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label Encoding\n",
    "dummy_data = pd.get_dummies(extracted_features_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4758d3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dysphonia</th>\n",
       "      <th>Laryngitis</th>\n",
       "      <th>Normal</th>\n",
       "      <th>Recurrent palsy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>929 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dysphonia  Laryngitis  Normal  Recurrent palsy\n",
       "0        False       False    True            False\n",
       "1        False       False    True            False\n",
       "2        False       False    True            False\n",
       "3        False       False    True            False\n",
       "4        False       False    True            False\n",
       "..         ...         ...     ...              ...\n",
       "924      False       False   False             True\n",
       "925      False       False   False             True\n",
       "926      False       False   False             True\n",
       "927      False       False   False             True\n",
       "928      False       False   False             True\n",
       "\n",
       "[929 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b543b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(extracted_features_df['feature'].values.tolist())\n",
    "y=dummy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "302d1f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929, 80)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faca9110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7262660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,stratify= y, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e1d6d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(743, 80)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81e0a1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186, 80)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70ec852f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(743, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48321029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff207eb",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d59d97d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3c49c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0586ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## No. of classes\n",
    "num_labels=y.shape[1]\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06adc7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "## first layer\n",
    "model.add(Dense(256,input_shape=(80,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "## second layer\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "## third layer\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "## final Layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e79dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94095501",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               20736     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 220164 (860.02 KB)\n",
      "Trainable params: 220164 (860.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "727a1c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 16.6896 - accuracy: 0.3553\n",
      "Epoch 1: val_loss improved from inf to 4.00914, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 2s 36ms/step - loss: 15.7269 - accuracy: 0.3580 - val_loss: 4.0091 - val_accuracy: 0.4624\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - ETA: 0s - loss: 8.2502 - accuracy: 0.3661\n",
      "Epoch 2: val_loss improved from 4.00914 to 1.56141, saving model to /audio_classification.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 9ms/step - loss: 8.2502 - accuracy: 0.3661 - val_loss: 1.5614 - val_accuracy: 0.4677\n",
      "Epoch 3/150\n",
      "12/24 [==============>...............] - ETA: 0s - loss: 5.4618 - accuracy: 0.4167\n",
      "Epoch 3: val_loss improved from 1.56141 to 1.25067, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 5.1394 - accuracy: 0.3917 - val_loss: 1.2507 - val_accuracy: 0.4839\n",
      "Epoch 4/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 3.7309 - accuracy: 0.4109\n",
      "Epoch 4: val_loss improved from 1.25067 to 1.16445, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 3.6661 - accuracy: 0.4145 - val_loss: 1.1645 - val_accuracy: 0.4462\n",
      "Epoch 5/150\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 2.9739 - accuracy: 0.3594\n",
      "Epoch 5: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 2.9403 - accuracy: 0.3580 - val_loss: 1.2001 - val_accuracy: 0.4785\n",
      "Epoch 6/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 2.4119 - accuracy: 0.4196\n",
      "Epoch 6: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 2.3295 - accuracy: 0.4253 - val_loss: 1.2503 - val_accuracy: 0.5054\n",
      "Epoch 7/150\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 2.0047 - accuracy: 0.4347\n",
      "Epoch 7: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.0077 - accuracy: 0.4307 - val_loss: 1.2348 - val_accuracy: 0.4946\n",
      "Epoch 8/150\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.7564 - accuracy: 0.4517\n",
      "Epoch 8: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.7532 - accuracy: 0.4482 - val_loss: 1.2937 - val_accuracy: 0.4731\n",
      "Epoch 9/150\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 1.6373 - accuracy: 0.4357\n",
      "Epoch 9: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.6220 - accuracy: 0.4428 - val_loss: 1.2576 - val_accuracy: 0.4839\n",
      "Epoch 10/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 1.6287 - accuracy: 0.4196\n",
      "Epoch 10: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.6255 - accuracy: 0.4199 - val_loss: 1.2370 - val_accuracy: 0.4946\n",
      "Epoch 11/150\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.4651 - accuracy: 0.4418\n",
      "Epoch 11: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.4660 - accuracy: 0.4455 - val_loss: 1.3042 - val_accuracy: 0.5054\n",
      "Epoch 12/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 1.5002 - accuracy: 0.4132\n",
      "Epoch 12: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.5044 - accuracy: 0.4038 - val_loss: 1.2918 - val_accuracy: 0.4946\n",
      "Epoch 13/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 1.3183 - accuracy: 0.4836\n",
      "Epoch 13: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.3147 - accuracy: 0.4872 - val_loss: 1.2842 - val_accuracy: 0.4301\n",
      "Epoch 14/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 1.3775 - accuracy: 0.4323\n",
      "Epoch 14: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.3481 - accuracy: 0.4441 - val_loss: 1.3066 - val_accuracy: 0.4301\n",
      "Epoch 15/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 1.3410 - accuracy: 0.4359\n",
      "Epoch 15: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.3370 - accuracy: 0.4347 - val_loss: 1.2954 - val_accuracy: 0.4516\n",
      "Epoch 16/150\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.3129 - accuracy: 0.4361\n",
      "Epoch 16: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.3161 - accuracy: 0.4428 - val_loss: 1.2918 - val_accuracy: 0.4194\n",
      "Epoch 17/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 1.3323 - accuracy: 0.4449\n",
      "Epoch 17: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.3357 - accuracy: 0.4415 - val_loss: 1.2789 - val_accuracy: 0.4247\n",
      "Epoch 18/150\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.1916 - accuracy: 0.4759\n",
      "Epoch 18: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.1834 - accuracy: 0.4791 - val_loss: 1.2592 - val_accuracy: 0.4462\n",
      "Epoch 19/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 1.2679 - accuracy: 0.4688\n",
      "Epoch 19: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.2784 - accuracy: 0.4536 - val_loss: 1.2320 - val_accuracy: 0.4624\n",
      "Epoch 20/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 1.2773 - accuracy: 0.4601\n",
      "Epoch 20: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.2757 - accuracy: 0.4576 - val_loss: 1.2265 - val_accuracy: 0.4516\n",
      "Epoch 21/150\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 1.2297 - accuracy: 0.4076\n",
      "Epoch 21: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.2280 - accuracy: 0.4092 - val_loss: 1.2186 - val_accuracy: 0.4462\n",
      "Epoch 22/150\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 1.1821 - accuracy: 0.4816\n",
      "Epoch 22: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.1761 - accuracy: 0.4791 - val_loss: 1.1882 - val_accuracy: 0.4247\n",
      "Epoch 23/150\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 1.2121 - accuracy: 0.4743\n",
      "Epoch 23: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.2149 - accuracy: 0.4724 - val_loss: 1.2194 - val_accuracy: 0.4355\n",
      "Epoch 24/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 1.2088 - accuracy: 0.4851\n",
      "Epoch 24: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.2119 - accuracy: 0.4805 - val_loss: 1.2153 - val_accuracy: 0.4570\n",
      "Epoch 25/150\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 1.2008 - accuracy: 0.4639\n",
      "Epoch 25: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.1705 - accuracy: 0.4791 - val_loss: 1.2332 - val_accuracy: 0.4194\n",
      "Epoch 26/150\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 1.1619 - accuracy: 0.4688\n",
      "Epoch 26: val_loss did not improve from 1.16445\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.1653 - accuracy: 0.4778 - val_loss: 1.1831 - val_accuracy: 0.4355\n",
      "Epoch 27/150\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.1754 - accuracy: 0.5014\n",
      "Epoch 27: val_loss improved from 1.16445 to 1.15697, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.1774 - accuracy: 0.5007 - val_loss: 1.1570 - val_accuracy: 0.4409\n",
      "Epoch 28/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 1.1523 - accuracy: 0.4836\n",
      "Epoch 28: val_loss did not improve from 1.15697\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.1389 - accuracy: 0.4859 - val_loss: 1.1595 - val_accuracy: 0.4462\n",
      "Epoch 29/150\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.1569 - accuracy: 0.4943\n",
      "Epoch 29: val_loss improved from 1.15697 to 1.14476, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.1534 - accuracy: 0.4980 - val_loss: 1.1448 - val_accuracy: 0.4570\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - ETA: 0s - loss: 1.1488 - accuracy: 0.5074\n",
      "Epoch 30: val_loss improved from 1.14476 to 1.14230, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.1488 - accuracy: 0.5074 - val_loss: 1.1423 - val_accuracy: 0.4462\n",
      "Epoch 31/150\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 1.1575 - accuracy: 0.4905\n",
      "Epoch 31: val_loss did not improve from 1.14230\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.1567 - accuracy: 0.4899 - val_loss: 1.1612 - val_accuracy: 0.4785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/150\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.1107 - accuracy: 0.5014\n",
      "Epoch 32: val_loss did not improve from 1.14230\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.1086 - accuracy: 0.5074 - val_loss: 1.1430 - val_accuracy: 0.4946\n",
      "Epoch 33/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 1.1940 - accuracy: 0.4953\n",
      "Epoch 33: val_loss improved from 1.14230 to 1.10716, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.1859 - accuracy: 0.5047 - val_loss: 1.1072 - val_accuracy: 0.5108\n",
      "Epoch 34/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 1.1444 - accuracy: 0.5226\n",
      "Epoch 34: val_loss did not improve from 1.10716\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.1522 - accuracy: 0.5047 - val_loss: 1.1376 - val_accuracy: 0.4839\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - ETA: 0s - loss: 1.1100 - accuracy: 0.5034\n",
      "Epoch 35: val_loss did not improve from 1.10716\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.1100 - accuracy: 0.5034 - val_loss: 1.1363 - val_accuracy: 0.4839\n",
      "Epoch 36/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 1.1248 - accuracy: 0.5016\n",
      "Epoch 36: val_loss did not improve from 1.10716\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.1034 - accuracy: 0.5101 - val_loss: 1.1375 - val_accuracy: 0.5000\n",
      "Epoch 37/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 1.1315 - accuracy: 0.4807\n",
      "Epoch 37: val_loss did not improve from 1.10716\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.1300 - accuracy: 0.4778 - val_loss: 1.1238 - val_accuracy: 0.5000\n",
      "Epoch 38/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 1.1101 - accuracy: 0.5125\n",
      "Epoch 38: val_loss did not improve from 1.10716\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.1098 - accuracy: 0.5101 - val_loss: 1.1297 - val_accuracy: 0.5161\n",
      "Epoch 39/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 1.0683 - accuracy: 0.5469\n",
      "Epoch 39: val_loss improved from 1.10716 to 1.10099, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.0737 - accuracy: 0.5437 - val_loss: 1.1010 - val_accuracy: 0.5215\n",
      "Epoch 40/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 1.1062 - accuracy: 0.5104\n",
      "Epoch 40: val_loss improved from 1.10099 to 1.10084, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0997 - accuracy: 0.5074 - val_loss: 1.1008 - val_accuracy: 0.5000\n",
      "Epoch 41/150\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.0956 - accuracy: 0.5128\n",
      "Epoch 41: val_loss did not improve from 1.10084\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0921 - accuracy: 0.5128 - val_loss: 1.1194 - val_accuracy: 0.4624\n",
      "Epoch 42/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 1.1124 - accuracy: 0.4922\n",
      "Epoch 42: val_loss did not improve from 1.10084\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.1052 - accuracy: 0.5007 - val_loss: 1.1241 - val_accuracy: 0.5000\n",
      "Epoch 43/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 1.0842 - accuracy: 0.5214\n",
      "Epoch 43: val_loss did not improve from 1.10084\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0724 - accuracy: 0.5303 - val_loss: 1.1114 - val_accuracy: 0.4946\n",
      "Epoch 44/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 1.1180 - accuracy: 0.5141\n",
      "Epoch 44: val_loss did not improve from 1.10084\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.1071 - accuracy: 0.5168 - val_loss: 1.1297 - val_accuracy: 0.4892\n",
      "Epoch 45/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 1.0826 - accuracy: 0.5281\n",
      "Epoch 45: val_loss improved from 1.10084 to 1.09104, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.1112 - accuracy: 0.5168 - val_loss: 1.0910 - val_accuracy: 0.5591\n",
      "Epoch 46/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 1.0649 - accuracy: 0.5164\n",
      "Epoch 46: val_loss did not improve from 1.09104\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0521 - accuracy: 0.5236 - val_loss: 1.1034 - val_accuracy: 0.5108\n",
      "Epoch 47/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 1.0393 - accuracy: 0.5411\n",
      "Epoch 47: val_loss did not improve from 1.09104\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0586 - accuracy: 0.5384 - val_loss: 1.0922 - val_accuracy: 0.5430\n",
      "Epoch 48/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 1.1099 - accuracy: 0.5049\n",
      "Epoch 48: val_loss did not improve from 1.09104\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0943 - accuracy: 0.5087 - val_loss: 1.1133 - val_accuracy: 0.5269\n",
      "Epoch 49/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 1.0155 - accuracy: 0.5399\n",
      "Epoch 49: val_loss improved from 1.09104 to 1.07777, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.0370 - accuracy: 0.5303 - val_loss: 1.0778 - val_accuracy: 0.5699\n",
      "Epoch 50/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 1.0187 - accuracy: 0.5747\n",
      "Epoch 50: val_loss improved from 1.07777 to 1.06906, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.0257 - accuracy: 0.5693 - val_loss: 1.0691 - val_accuracy: 0.5538\n",
      "Epoch 51/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 1.0982 - accuracy: 0.5223\n",
      "Epoch 51: val_loss did not improve from 1.06906\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0883 - accuracy: 0.5276 - val_loss: 1.0982 - val_accuracy: 0.4839\n",
      "Epoch 52/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 1.0692 - accuracy: 0.5226\n",
      "Epoch 52: val_loss did not improve from 1.06906\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0498 - accuracy: 0.5410 - val_loss: 1.0850 - val_accuracy: 0.5215\n",
      "Epoch 53/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 1.0459 - accuracy: 0.5573\n",
      "Epoch 53: val_loss improved from 1.06906 to 1.05815, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.0071 - accuracy: 0.5707 - val_loss: 1.0582 - val_accuracy: 0.5591\n",
      "Epoch 54/150\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.0722 - accuracy: 0.5298\n",
      "Epoch 54: val_loss did not improve from 1.05815\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0682 - accuracy: 0.5262 - val_loss: 1.0728 - val_accuracy: 0.5376\n",
      "Epoch 55/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 1.0578 - accuracy: 0.5491\n",
      "Epoch 55: val_loss did not improve from 1.05815\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.0523 - accuracy: 0.5518 - val_loss: 1.1014 - val_accuracy: 0.4946\n",
      "Epoch 56/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 1.0175 - accuracy: 0.5559\n",
      "Epoch 56: val_loss did not improve from 1.05815\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0115 - accuracy: 0.5585 - val_loss: 1.0755 - val_accuracy: 0.5484\n",
      "Epoch 57/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 1.0081 - accuracy: 0.5641\n",
      "Epoch 57: val_loss did not improve from 1.05815\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0342 - accuracy: 0.5585 - val_loss: 1.0700 - val_accuracy: 0.5430\n",
      "Epoch 58/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 1.0344 - accuracy: 0.5362\n",
      "Epoch 58: val_loss did not improve from 1.05815\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.0186 - accuracy: 0.5451 - val_loss: 1.0587 - val_accuracy: 0.5538\n",
      "Epoch 59/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 1.0107 - accuracy: 0.5714\n",
      "Epoch 59: val_loss improved from 1.05815 to 1.04847, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.9929 - accuracy: 0.5787 - val_loss: 1.0485 - val_accuracy: 0.5484\n",
      "Epoch 60/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 1.0240 - accuracy: 0.5500\n",
      "Epoch 60: val_loss did not improve from 1.04847\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0312 - accuracy: 0.5505 - val_loss: 1.0491 - val_accuracy: 0.5484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.9978 - accuracy: 0.5691\n",
      "Epoch 61: val_loss improved from 1.04847 to 1.03542, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.9812 - accuracy: 0.5787 - val_loss: 1.0354 - val_accuracy: 0.5914\n",
      "Epoch 62/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 1.0055 - accuracy: 0.5719\n",
      "Epoch 62: val_loss did not improve from 1.03542\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0126 - accuracy: 0.5572 - val_loss: 1.0450 - val_accuracy: 0.5538\n",
      "Epoch 63/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 1.0037 - accuracy: 0.6101\n",
      "Epoch 63: val_loss did not improve from 1.03542\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0059 - accuracy: 0.5949 - val_loss: 1.0617 - val_accuracy: 0.5215\n",
      "Epoch 64/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.9697 - accuracy: 0.5906\n",
      "Epoch 64: val_loss did not improve from 1.03542\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.9839 - accuracy: 0.5868 - val_loss: 1.0472 - val_accuracy: 0.5591\n",
      "Epoch 65/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.9911 - accuracy: 0.5833\n",
      "Epoch 65: val_loss did not improve from 1.03542\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.9964 - accuracy: 0.5841 - val_loss: 1.0511 - val_accuracy: 0.5645\n",
      "Epoch 66/150\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.9125 - accuracy: 0.6130\n",
      "Epoch 66: val_loss did not improve from 1.03542\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.9800 - accuracy: 0.5828 - val_loss: 1.0512 - val_accuracy: 0.5699\n",
      "Epoch 67/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 1.0030 - accuracy: 0.5908\n",
      "Epoch 67: val_loss improved from 1.03542 to 1.03365, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.9938 - accuracy: 0.5868 - val_loss: 1.0337 - val_accuracy: 0.5806\n",
      "Epoch 68/150\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.9738 - accuracy: 0.5781\n",
      "Epoch 68: val_loss did not improve from 1.03365\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.9715 - accuracy: 0.5774 - val_loss: 1.0521 - val_accuracy: 0.5591\n",
      "Epoch 69/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.9707 - accuracy: 0.6012\n",
      "Epoch 69: val_loss did not improve from 1.03365\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.9815 - accuracy: 0.5962 - val_loss: 1.0776 - val_accuracy: 0.5323\n",
      "Epoch 70/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.9632 - accuracy: 0.5844\n",
      "Epoch 70: val_loss did not improve from 1.03365\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.9676 - accuracy: 0.5787 - val_loss: 1.0386 - val_accuracy: 0.5591\n",
      "Epoch 71/150\n",
      "15/24 [=================>............] - ETA: 0s - loss: 0.9327 - accuracy: 0.6187\n",
      "Epoch 71: val_loss improved from 1.03365 to 1.02058, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.9389 - accuracy: 0.6070 - val_loss: 1.0206 - val_accuracy: 0.5806\n",
      "Epoch 72/150\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.9169 - accuracy: 0.6103\n",
      "Epoch 72: val_loss did not improve from 1.02058\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.9251 - accuracy: 0.6151 - val_loss: 1.0248 - val_accuracy: 0.5753\n",
      "Epoch 73/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.9924 - accuracy: 0.5921\n",
      "Epoch 73: val_loss did not improve from 1.02058\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.9687 - accuracy: 0.5989 - val_loss: 1.0396 - val_accuracy: 0.5484\n",
      "Epoch 74/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.9342 - accuracy: 0.6078\n",
      "Epoch 74: val_loss did not improve from 1.02058\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.9490 - accuracy: 0.5949 - val_loss: 1.0330 - val_accuracy: 0.5699\n",
      "Epoch 75/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.9506 - accuracy: 0.5997\n",
      "Epoch 75: val_loss did not improve from 1.02058\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.9403 - accuracy: 0.5989 - val_loss: 1.0476 - val_accuracy: 0.5323\n",
      "Epoch 76/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.9120 - accuracy: 0.5833\n",
      "Epoch 76: val_loss did not improve from 1.02058\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.9154 - accuracy: 0.5855 - val_loss: 1.0640 - val_accuracy: 0.5323\n",
      "Epoch 77/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.9359 - accuracy: 0.6031\n",
      "Epoch 77: val_loss did not improve from 1.02058\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.9337 - accuracy: 0.6043 - val_loss: 1.0312 - val_accuracy: 0.5699\n",
      "Epoch 78/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.9270 - accuracy: 0.6027\n",
      "Epoch 78: val_loss did not improve from 1.02058\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.9443 - accuracy: 0.5908 - val_loss: 1.0358 - val_accuracy: 0.5591\n",
      "Epoch 79/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.8905 - accuracy: 0.6250\n",
      "Epoch 79: val_loss did not improve from 1.02058\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.9093 - accuracy: 0.6164 - val_loss: 1.0240 - val_accuracy: 0.5538\n",
      "Epoch 80/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.8967 - accuracy: 0.6003\n",
      "Epoch 80: val_loss did not improve from 1.02058\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.8961 - accuracy: 0.6043 - val_loss: 1.0209 - val_accuracy: 0.5376\n",
      "Epoch 81/150\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.9316 - accuracy: 0.6321\n",
      "Epoch 81: val_loss did not improve from 1.02058\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.9252 - accuracy: 0.6380 - val_loss: 1.0358 - val_accuracy: 0.5699\n",
      "Epoch 82/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.9116 - accuracy: 0.6047\n",
      "Epoch 82: val_loss did not improve from 1.02058\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.9160 - accuracy: 0.5962 - val_loss: 1.0350 - val_accuracy: 0.5645\n",
      "Epoch 83/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.9060 - accuracy: 0.6042\n",
      "Epoch 83: val_loss improved from 1.02058 to 1.01288, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.8885 - accuracy: 0.6083 - val_loss: 1.0129 - val_accuracy: 0.5538\n",
      "Epoch 84/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.9042 - accuracy: 0.6266\n",
      "Epoch 84: val_loss improved from 1.01288 to 1.01031, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.9154 - accuracy: 0.6178 - val_loss: 1.0103 - val_accuracy: 0.5699\n",
      "Epoch 85/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.9103 - accuracy: 0.6220\n",
      "Epoch 85: val_loss did not improve from 1.01031\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.8976 - accuracy: 0.6245 - val_loss: 1.0205 - val_accuracy: 0.5538\n",
      "Epoch 86/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.8725 - accuracy: 0.6280\n",
      "Epoch 86: val_loss improved from 1.01031 to 1.00843, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.8709 - accuracy: 0.6312 - val_loss: 1.0084 - val_accuracy: 0.5806\n",
      "Epoch 87/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.8066 - accuracy: 0.6406\n",
      "Epoch 87: val_loss did not improve from 1.00843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.8231 - accuracy: 0.6366 - val_loss: 1.0252 - val_accuracy: 0.5591\n",
      "Epoch 88/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.8864 - accuracy: 0.6176\n",
      "Epoch 88: val_loss improved from 1.00843 to 1.00690, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.8867 - accuracy: 0.6124 - val_loss: 1.0069 - val_accuracy: 0.5968\n",
      "Epoch 89/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.8457 - accuracy: 0.6464\n",
      "Epoch 89: val_loss did not improve from 1.00690\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.8750 - accuracy: 0.6420 - val_loss: 1.0158 - val_accuracy: 0.5753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/150\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.8868 - accuracy: 0.6158\n",
      "Epoch 90: val_loss improved from 1.00690 to 1.00597, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.8719 - accuracy: 0.6285 - val_loss: 1.0060 - val_accuracy: 0.5645\n",
      "Epoch 91/150\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.8460 - accuracy: 0.6434\n",
      "Epoch 91: val_loss did not improve from 1.00597\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.8535 - accuracy: 0.6366 - val_loss: 1.0117 - val_accuracy: 0.5860\n",
      "Epoch 92/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.8402 - accuracy: 0.6266\n",
      "Epoch 92: val_loss did not improve from 1.00597\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.8284 - accuracy: 0.6339 - val_loss: 1.0288 - val_accuracy: 0.5591\n",
      "Epoch 93/150\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.8377 - accuracy: 0.6434\n",
      "Epoch 93: val_loss did not improve from 1.00597\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.8209 - accuracy: 0.6420 - val_loss: 1.0325 - val_accuracy: 0.5591\n",
      "Epoch 94/150\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.8076 - accuracy: 0.6630\n",
      "Epoch 94: val_loss did not improve from 1.00597\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 0.8045 - accuracy: 0.6635 - val_loss: 1.0072 - val_accuracy: 0.5806\n",
      "Epoch 95/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.8385 - accuracy: 0.6562\n",
      "Epoch 95: val_loss did not improve from 1.00597\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.8414 - accuracy: 0.6541 - val_loss: 1.0127 - val_accuracy: 0.5968\n",
      "Epoch 96/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.7831 - accuracy: 0.6750\n",
      "Epoch 96: val_loss did not improve from 1.00597\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7991 - accuracy: 0.6568 - val_loss: 1.0188 - val_accuracy: 0.5860\n",
      "Epoch 97/150\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.8025 - accuracy: 0.6342\n",
      "Epoch 97: val_loss did not improve from 1.00597\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.8067 - accuracy: 0.6474 - val_loss: 1.0327 - val_accuracy: 0.5591\n",
      "Epoch 98/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.8535 - accuracy: 0.6424\n",
      "Epoch 98: val_loss did not improve from 1.00597\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.8427 - accuracy: 0.6528 - val_loss: 1.0297 - val_accuracy: 0.5860\n",
      "Epoch 99/150\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.8607 - accuracy: 0.6324\n",
      "Epoch 99: val_loss did not improve from 1.00597\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.8291 - accuracy: 0.6460 - val_loss: 1.0377 - val_accuracy: 0.5376\n",
      "Epoch 100/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.7522 - accuracy: 0.6771\n",
      "Epoch 100: val_loss did not improve from 1.00597\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7803 - accuracy: 0.6676 - val_loss: 1.0385 - val_accuracy: 0.5699\n",
      "Epoch 101/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.7890 - accuracy: 0.6687\n",
      "Epoch 101: val_loss did not improve from 1.00597\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.8006 - accuracy: 0.6703 - val_loss: 1.0394 - val_accuracy: 0.5806\n",
      "Epoch 102/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.8072 - accuracy: 0.6597\n",
      "Epoch 102: val_loss did not improve from 1.00597\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7991 - accuracy: 0.6729 - val_loss: 1.0432 - val_accuracy: 0.5914\n",
      "Epoch 103/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.7966 - accuracy: 0.6562\n",
      "Epoch 103: val_loss improved from 1.00597 to 1.00305, saving model to /audio_classification.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7950 - accuracy: 0.6541 - val_loss: 1.0031 - val_accuracy: 0.5914\n",
      "Epoch 104/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.7660 - accuracy: 0.6678\n",
      "Epoch 104: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.7811 - accuracy: 0.6635 - val_loss: 1.0165 - val_accuracy: 0.5591\n",
      "Epoch 105/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.7765 - accuracy: 0.6656\n",
      "Epoch 105: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.7781 - accuracy: 0.6703 - val_loss: 1.0517 - val_accuracy: 0.5484\n",
      "Epoch 106/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.7616 - accuracy: 0.6908\n",
      "Epoch 106: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7758 - accuracy: 0.6770 - val_loss: 1.0271 - val_accuracy: 0.5806\n",
      "Epoch 107/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.7714 - accuracy: 0.6815\n",
      "Epoch 107: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.7715 - accuracy: 0.6810 - val_loss: 1.0489 - val_accuracy: 0.5484\n",
      "Epoch 108/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.7492 - accuracy: 0.6941\n",
      "Epoch 108: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7593 - accuracy: 0.6878 - val_loss: 1.0428 - val_accuracy: 0.5484\n",
      "Epoch 109/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.7602 - accuracy: 0.7007\n",
      "Epoch 109: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7591 - accuracy: 0.6999 - val_loss: 1.0272 - val_accuracy: 0.5376\n",
      "Epoch 110/150\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.7263 - accuracy: 0.6945\n",
      "Epoch 110: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.7263 - accuracy: 0.6945 - val_loss: 1.0199 - val_accuracy: 0.5699\n",
      "Epoch 111/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.7072 - accuracy: 0.7078\n",
      "Epoch 111: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.7126 - accuracy: 0.7052 - val_loss: 1.0531 - val_accuracy: 0.5484\n",
      "Epoch 112/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.7083 - accuracy: 0.7101\n",
      "Epoch 112: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7267 - accuracy: 0.6931 - val_loss: 1.0481 - val_accuracy: 0.5269\n",
      "Epoch 113/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.7140 - accuracy: 0.7125\n",
      "Epoch 113: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.7212 - accuracy: 0.7133 - val_loss: 1.0591 - val_accuracy: 0.5376\n",
      "Epoch 114/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.7422 - accuracy: 0.7016\n",
      "Epoch 114: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.7564 - accuracy: 0.6945 - val_loss: 1.0531 - val_accuracy: 0.5376\n",
      "Epoch 115/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.7062 - accuracy: 0.7023\n",
      "Epoch 115: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.7037 - accuracy: 0.7039 - val_loss: 1.0508 - val_accuracy: 0.5430\n",
      "Epoch 116/150\n",
      "16/24 [===================>..........] - ETA: 0s - loss: 0.6919 - accuracy: 0.7188\n",
      "Epoch 116: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6989 - accuracy: 0.7160 - val_loss: 1.0565 - val_accuracy: 0.5484\n",
      "Epoch 117/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.7342 - accuracy: 0.7007\n",
      "Epoch 117: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7235 - accuracy: 0.6999 - val_loss: 1.0758 - val_accuracy: 0.5699\n",
      "Epoch 118/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.7042 - accuracy: 0.6910\n",
      "Epoch 118: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7143 - accuracy: 0.6945 - val_loss: 1.1116 - val_accuracy: 0.5699\n",
      "Epoch 119/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.6906 - accuracy: 0.7361\n",
      "Epoch 119: val_loss did not improve from 1.00305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7049 - accuracy: 0.7295 - val_loss: 1.0831 - val_accuracy: 0.5430\n",
      "Epoch 120/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.6797 - accuracy: 0.7170\n",
      "Epoch 120: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6812 - accuracy: 0.7147 - val_loss: 1.0744 - val_accuracy: 0.5269\n",
      "Epoch 121/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.7190 - accuracy: 0.7089\n",
      "Epoch 121: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.7036 - accuracy: 0.7133 - val_loss: 1.0528 - val_accuracy: 0.5645\n",
      "Epoch 122/150\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6709 - accuracy: 0.7145\n",
      "Epoch 122: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.6673 - accuracy: 0.7201 - val_loss: 1.0803 - val_accuracy: 0.5161\n",
      "Epoch 123/150\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.6585 - accuracy: 0.7337\n",
      "Epoch 123: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.6592 - accuracy: 0.7349 - val_loss: 1.0769 - val_accuracy: 0.5376\n",
      "Epoch 124/150\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.6525 - accuracy: 0.7337\n",
      "Epoch 124: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.6489 - accuracy: 0.7349 - val_loss: 1.1408 - val_accuracy: 0.5484\n",
      "Epoch 125/150\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.7065\n",
      "Epoch 125: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.6958 - accuracy: 0.7052 - val_loss: 1.0831 - val_accuracy: 0.4946\n",
      "Epoch 126/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.6886 - accuracy: 0.7188\n",
      "Epoch 126: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6846 - accuracy: 0.7214 - val_loss: 1.1282 - val_accuracy: 0.5591\n",
      "Epoch 127/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.6621 - accuracy: 0.7188\n",
      "Epoch 127: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6627 - accuracy: 0.7214 - val_loss: 1.0972 - val_accuracy: 0.5376\n",
      "Epoch 128/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.6298 - accuracy: 0.7375\n",
      "Epoch 128: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6345 - accuracy: 0.7362 - val_loss: 1.1103 - val_accuracy: 0.5376\n",
      "Epoch 129/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.6481 - accuracy: 0.7361\n",
      "Epoch 129: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6468 - accuracy: 0.7429 - val_loss: 1.1422 - val_accuracy: 0.5108\n",
      "Epoch 130/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.6685 - accuracy: 0.7066\n",
      "Epoch 130: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6724 - accuracy: 0.7133 - val_loss: 1.1095 - val_accuracy: 0.5269\n",
      "Epoch 131/150\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6358 - accuracy: 0.7132\n",
      "Epoch 131: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6267 - accuracy: 0.7147 - val_loss: 1.1462 - val_accuracy: 0.5591\n",
      "Epoch 132/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.5729 - accuracy: 0.7766\n",
      "Epoch 132: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.5696 - accuracy: 0.7766 - val_loss: 1.1748 - val_accuracy: 0.5430\n",
      "Epoch 133/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.6443 - accuracy: 0.7484\n",
      "Epoch 133: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6424 - accuracy: 0.7389 - val_loss: 1.1587 - val_accuracy: 0.5215\n",
      "Epoch 134/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.5834 - accuracy: 0.7549\n",
      "Epoch 134: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5869 - accuracy: 0.7550 - val_loss: 1.2100 - val_accuracy: 0.5323\n",
      "Epoch 135/150\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6485 - accuracy: 0.7316\n",
      "Epoch 135: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6238 - accuracy: 0.7389 - val_loss: 1.1680 - val_accuracy: 0.4892\n",
      "Epoch 136/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.6139 - accuracy: 0.7437\n",
      "Epoch 136: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6052 - accuracy: 0.7470 - val_loss: 1.2027 - val_accuracy: 0.5269\n",
      "Epoch 137/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.5580 - accuracy: 0.7708\n",
      "Epoch 137: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5754 - accuracy: 0.7672 - val_loss: 1.1880 - val_accuracy: 0.4892\n",
      "Epoch 138/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.5320 - accuracy: 0.7796\n",
      "Epoch 138: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.5382 - accuracy: 0.7820 - val_loss: 1.2449 - val_accuracy: 0.5054\n",
      "Epoch 139/150\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5945 - accuracy: 0.7776\n",
      "Epoch 139: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5942 - accuracy: 0.7604 - val_loss: 1.2927 - val_accuracy: 0.5000\n",
      "Epoch 140/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.6290 - accuracy: 0.7560\n",
      "Epoch 140: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.6183 - accuracy: 0.7591 - val_loss: 1.1826 - val_accuracy: 0.4892\n",
      "Epoch 141/150\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.5821 - accuracy: 0.7530\n",
      "Epoch 141: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.5953 - accuracy: 0.7470 - val_loss: 1.1945 - val_accuracy: 0.5215\n",
      "Epoch 142/150\n",
      "16/24 [===================>..........] - ETA: 0s - loss: 0.6610 - accuracy: 0.7480\n",
      "Epoch 142: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6292 - accuracy: 0.7456 - val_loss: 1.1845 - val_accuracy: 0.5108\n",
      "Epoch 143/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.5490 - accuracy: 0.7533\n",
      "Epoch 143: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.5675 - accuracy: 0.7443 - val_loss: 1.2566 - val_accuracy: 0.5161\n",
      "Epoch 144/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.6528 - accuracy: 0.7281\n",
      "Epoch 144: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6443 - accuracy: 0.7362 - val_loss: 1.2785 - val_accuracy: 0.5215\n",
      "Epoch 145/150\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5349 - accuracy: 0.7713\n",
      "Epoch 145: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5290 - accuracy: 0.7766 - val_loss: 1.3047 - val_accuracy: 0.5108\n",
      "Epoch 146/150\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5276 - accuracy: 0.7756\n",
      "Epoch 146: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5319 - accuracy: 0.7712 - val_loss: 1.2504 - val_accuracy: 0.5054\n",
      "Epoch 147/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.5491 - accuracy: 0.7688\n",
      "Epoch 147: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.5469 - accuracy: 0.7766 - val_loss: 1.2220 - val_accuracy: 0.5323\n",
      "Epoch 148/150\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.5059 - accuracy: 0.7969\n",
      "Epoch 148: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5379 - accuracy: 0.7793 - val_loss: 1.2535 - val_accuracy: 0.5000\n",
      "Epoch 149/150\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.5492 - accuracy: 0.7780\n",
      "Epoch 149: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5510 - accuracy: 0.7779 - val_loss: 1.2116 - val_accuracy: 0.5054\n",
      "Epoch 150/150\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.5211 - accuracy: 0.7875\n",
      "Epoch 150: val_loss did not improve from 1.00305\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.5374 - accuracy: 0.7766 - val_loss: 1.2373 - val_accuracy: 0.5161\n",
      "Training completed in time:  0:00:33.026727\n"
     ]
    }
   ],
   "source": [
    "## Training my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "num_epochs=150\n",
    "num_batch_size=32\n",
    "\n",
    "checkpointer=ModelCheckpoint(filepath='/audio_classification.hdf5', verbose=1, save_best_only=True)\n",
    "start=datetime.now() \n",
    "\n",
    "model.fit(x_train,y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test,y_test), callbacks=[checkpointer])\n",
    "duration=datetime.now()-start\n",
    "\n",
    "print(\"Training completed in time: \",duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc371d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(x_test,y_test,verbose=0)\n",
    "print(test_accuracy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "105b6ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a327cebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.77128153e-04, 5.18115667e-06, 9.99817312e-01, 4.59028286e-07],\n",
       "       [5.50034344e-01, 7.07388222e-02, 2.64443815e-01, 1.14783049e-01],\n",
       "       [6.99112058e-01, 1.34799063e-01, 1.02776140e-01, 6.33127168e-02],\n",
       "       [2.77265549e-01, 2.59039132e-03, 7.12098241e-01, 8.04577768e-03],\n",
       "       [4.63720232e-01, 1.56213641e-01, 2.93880738e-02, 3.50678086e-01],\n",
       "       [3.36718738e-01, 1.10367119e-01, 2.58333497e-02, 5.27080715e-01],\n",
       "       [4.81332958e-01, 6.72308356e-02, 3.63754660e-01, 8.76815319e-02],\n",
       "       [3.10921413e-03, 2.21860060e-03, 9.94614184e-01, 5.80458182e-05],\n",
       "       [5.12891293e-01, 2.25305408e-02, 4.19385791e-01, 4.51923423e-02],\n",
       "       [2.81982094e-01, 2.47627981e-02, 5.87515473e-01, 1.05739631e-01],\n",
       "       [4.25583303e-01, 1.06832363e-01, 1.72803730e-01, 2.94780642e-01],\n",
       "       [1.31637156e-01, 6.96926890e-03, 8.27366292e-01, 3.40273008e-02],\n",
       "       [4.70108166e-02, 5.60868764e-03, 9.45570707e-01, 1.80979434e-03],\n",
       "       [1.75659254e-01, 1.26358494e-02, 7.89468765e-01, 2.22361665e-02],\n",
       "       [4.60319579e-01, 1.79664418e-01, 1.35025933e-01, 2.24990055e-01],\n",
       "       [3.16481113e-01, 8.91196653e-02, 1.47747889e-01, 4.46651399e-01],\n",
       "       [3.31727862e-01, 2.52160519e-01, 2.71587759e-01, 1.44523829e-01],\n",
       "       [4.59552417e-03, 5.60165104e-03, 9.89762008e-01, 4.08514388e-05],\n",
       "       [3.90624493e-01, 1.02454521e-01, 2.98368424e-01, 2.08552539e-01],\n",
       "       [2.67624825e-01, 8.60202834e-02, 2.40184274e-02, 6.22336507e-01],\n",
       "       [3.41726899e-01, 1.56254485e-01, 2.22292900e-01, 2.79725790e-01],\n",
       "       [7.91840535e-03, 6.22178632e-05, 9.91827607e-01, 1.91732994e-04],\n",
       "       [4.74526376e-01, 1.75815299e-01, 4.78385203e-02, 3.01819801e-01],\n",
       "       [4.12415802e-01, 5.06551303e-02, 4.71650302e-01, 6.52787685e-02],\n",
       "       [5.00038207e-01, 1.87711090e-01, 1.52271599e-01, 1.59979135e-01],\n",
       "       [6.02415716e-03, 6.66742853e-05, 9.93868530e-01, 4.06176005e-05],\n",
       "       [8.83619189e-01, 6.78414991e-03, 1.05257303e-01, 4.33932617e-03],\n",
       "       [1.87069252e-01, 4.01324481e-02, 6.24912620e-01, 1.47885740e-01],\n",
       "       [2.30032057e-01, 5.97653762e-02, 6.91113994e-03, 7.03291476e-01],\n",
       "       [4.72103447e-01, 1.39167123e-02, 4.93714482e-01, 2.02654116e-02],\n",
       "       [4.04095471e-01, 1.63247123e-01, 1.16238393e-01, 3.16418976e-01],\n",
       "       [5.47146022e-01, 1.43380761e-01, 1.00615807e-01, 2.08857447e-01],\n",
       "       [4.85033184e-01, 1.05758354e-01, 2.05367461e-01, 2.03841016e-01],\n",
       "       [3.93511169e-03, 3.46587103e-06, 9.96057153e-01, 4.27860459e-06],\n",
       "       [2.49230906e-01, 6.50090650e-02, 6.34571850e-01, 5.11882566e-02],\n",
       "       [4.65344965e-01, 1.44378707e-01, 1.96477771e-01, 1.93798617e-01],\n",
       "       [4.13537025e-01, 6.23077005e-02, 4.68898118e-01, 5.52571677e-02],\n",
       "       [5.37365139e-01, 1.93700552e-01, 1.35213509e-01, 1.33720756e-01],\n",
       "       [1.76824513e-04, 4.64803165e-08, 9.99823034e-01, 3.27849925e-08],\n",
       "       [1.99326754e-01, 1.60248846e-01, 1.56070352e-01, 4.84354109e-01],\n",
       "       [3.53654996e-02, 2.83035042e-05, 9.64235961e-01, 3.70248541e-04],\n",
       "       [8.24225008e-01, 3.55977230e-02, 1.27297148e-01, 1.28800506e-02],\n",
       "       [6.40468240e-01, 1.67997181e-02, 2.92093664e-01, 5.06383218e-02],\n",
       "       [6.26696215e-04, 9.40514511e-08, 9.99373138e-01, 1.00871496e-07],\n",
       "       [4.76434678e-01, 4.23198417e-02, 4.52801794e-01, 2.84437872e-02],\n",
       "       [4.16926563e-01, 1.34017374e-02, 5.57857513e-01, 1.18142171e-02],\n",
       "       [6.82147741e-02, 1.60034586e-04, 9.31143224e-01, 4.81983559e-04],\n",
       "       [3.58501732e-01, 2.18846604e-01, 8.37170556e-02, 3.38934571e-01],\n",
       "       [2.25626111e-01, 2.98072677e-03, 7.63346255e-01, 8.04696511e-03],\n",
       "       [5.01354109e-04, 1.20741831e-07, 9.99498487e-01, 5.38823137e-08],\n",
       "       [4.34737593e-01, 1.29947960e-01, 1.06718861e-01, 3.28595519e-01],\n",
       "       [5.64235495e-03, 1.86804209e-05, 9.94271755e-01, 6.72917595e-05],\n",
       "       [1.84015837e-02, 5.87937143e-03, 9.74848449e-01, 8.70618038e-04],\n",
       "       [3.67011100e-01, 7.21126422e-02, 3.54548186e-01, 2.06328109e-01],\n",
       "       [8.91146958e-01, 3.92919369e-02, 4.23200205e-02, 2.72410549e-02],\n",
       "       [2.59298056e-01, 1.24673471e-02, 7.00972080e-01, 2.72624549e-02],\n",
       "       [3.50325942e-01, 8.42612386e-02, 2.68210955e-02, 5.38591802e-01],\n",
       "       [7.05940574e-02, 8.54004931e-04, 9.25215840e-01, 3.33605078e-03],\n",
       "       [3.81157966e-04, 8.14238854e-04, 9.98801589e-01, 2.99415478e-06],\n",
       "       [3.18175048e-01, 8.47358406e-02, 2.35115245e-01, 3.61973912e-01],\n",
       "       [1.71072915e-01, 2.04937290e-02, 7.51843929e-01, 5.65894246e-02],\n",
       "       [7.03207180e-02, 2.44005141e-03, 9.22268152e-01, 4.97110886e-03],\n",
       "       [1.03994988e-01, 2.22256081e-03, 2.34456005e-04, 8.93548071e-01],\n",
       "       [4.51311946e-01, 2.55621858e-02, 3.87290984e-01, 1.35834888e-01],\n",
       "       [4.72351611e-02, 4.24243626e-04, 9.51311648e-01, 1.02892262e-03],\n",
       "       [3.35243791e-01, 2.09411964e-01, 4.11009192e-02, 4.14243340e-01],\n",
       "       [2.30774298e-01, 1.95360407e-02, 6.88541114e-01, 6.11484870e-02],\n",
       "       [2.43370533e-01, 3.68820280e-02, 1.12058921e-02, 7.08541572e-01],\n",
       "       [5.00100382e-14, 5.00405466e-15, 1.00000000e+00, 1.00734087e-20],\n",
       "       [7.70526171e-01, 2.79407352e-02, 1.58113986e-01, 4.34191823e-02],\n",
       "       [5.10324121e-01, 2.03301445e-01, 9.74559858e-02, 1.88918486e-01],\n",
       "       [3.62317380e-03, 3.97990807e-04, 9.95955884e-01, 2.28596473e-05],\n",
       "       [1.72342300e-01, 2.81061344e-02, 7.30869412e-01, 6.86820745e-02],\n",
       "       [4.32366103e-01, 1.71342552e-01, 1.13757715e-01, 2.82533616e-01],\n",
       "       [6.65248394e-01, 2.54069209e-01, 3.01936157e-02, 5.04887663e-02],\n",
       "       [3.71798664e-01, 7.82202557e-02, 2.05491439e-01, 3.44489545e-01],\n",
       "       [2.65785962e-01, 8.32985267e-02, 2.50200946e-02, 6.25895321e-01],\n",
       "       [3.14773411e-01, 1.00021996e-01, 2.59738386e-01, 3.25466216e-01],\n",
       "       [1.15242759e-02, 2.40338661e-04, 9.87991750e-01, 2.43656643e-04],\n",
       "       [2.00790763e-02, 2.70570489e-03, 9.77084458e-01, 1.30740096e-04],\n",
       "       [3.53273451e-01, 1.02276109e-01, 3.12256485e-01, 2.32193977e-01],\n",
       "       [5.81311226e-01, 6.75237626e-02, 2.60631055e-01, 9.05339494e-02],\n",
       "       [1.03839077e-01, 1.92210951e-04, 8.95937085e-01, 3.16014557e-05],\n",
       "       [8.50408971e-02, 5.59265213e-03, 8.99136126e-01, 1.02303401e-02],\n",
       "       [2.05949366e-01, 6.70768227e-03, 7.46861219e-01, 4.04816195e-02],\n",
       "       [3.78418088e-01, 1.56005798e-02, 5.63698292e-01, 4.22830060e-02],\n",
       "       [2.10918952e-03, 8.32091018e-09, 9.97890651e-01, 5.72338159e-08],\n",
       "       [2.49645606e-01, 1.59803927e-02, 1.16644748e-01, 6.17729306e-01],\n",
       "       [4.52374965e-01, 2.70787776e-01, 3.89400646e-02, 2.37897143e-01],\n",
       "       [4.62001102e-04, 6.27706640e-07, 1.03966194e-07, 9.99537349e-01],\n",
       "       [5.02851665e-01, 3.67044285e-02, 4.27402198e-01, 3.30417305e-02],\n",
       "       [3.38217080e-01, 8.86834934e-02, 3.52841407e-01, 2.20258072e-01],\n",
       "       [4.26912218e-01, 1.04806595e-01, 3.09326470e-01, 1.58954769e-01],\n",
       "       [3.87207657e-01, 6.56287596e-02, 4.16360736e-01, 1.30802870e-01],\n",
       "       [6.33827567e-01, 7.66034871e-02, 2.20136032e-01, 6.94329068e-02],\n",
       "       [4.66205448e-01, 1.08259074e-01, 1.56804308e-01, 2.68731177e-01],\n",
       "       [2.87920892e-01, 1.21999110e-04, 7.11742163e-01, 2.14883432e-04],\n",
       "       [4.23882872e-01, 7.82618597e-02, 1.65233746e-01, 3.32621515e-01],\n",
       "       [4.89049584e-01, 3.32561694e-02, 4.14948225e-01, 6.27460033e-02],\n",
       "       [6.11714184e-01, 4.62025441e-02, 2.76434898e-01, 6.56484142e-02],\n",
       "       [1.44832179e-01, 1.02244886e-02, 8.19756806e-01, 2.51865778e-02],\n",
       "       [3.37152839e-01, 6.22939430e-02, 6.48568422e-02, 5.35696387e-01],\n",
       "       [4.02774155e-01, 1.66611467e-02, 2.71084718e-02, 5.53456247e-01],\n",
       "       [2.04281449e-01, 1.81065369e-02, 7.63527453e-01, 1.40846549e-02],\n",
       "       [3.59301984e-01, 1.33776352e-01, 1.18427105e-01, 3.88494492e-01],\n",
       "       [1.14566453e-01, 2.02466006e-04, 8.84535551e-01, 6.95477007e-04],\n",
       "       [2.08598599e-02, 4.21400036e-04, 9.78455722e-01, 2.63068767e-04],\n",
       "       [1.00550450e-01, 1.22066867e-02, 8.79431903e-01, 7.81096751e-03],\n",
       "       [3.88854116e-01, 1.15544252e-01, 1.56747267e-01, 3.38854432e-01],\n",
       "       [3.91442567e-01, 7.96252936e-02, 3.58494788e-01, 1.70437276e-01],\n",
       "       [1.34925945e-02, 2.80018248e-05, 9.86443877e-01, 3.55461998e-05],\n",
       "       [8.37860331e-02, 5.26508084e-04, 8.99046600e-01, 1.66408550e-02],\n",
       "       [3.18390541e-02, 2.71902559e-03, 9.63818848e-01, 1.62296731e-03],\n",
       "       [1.76946610e-01, 2.18674988e-02, 7.76977718e-01, 2.42081843e-02],\n",
       "       [3.40411723e-01, 1.10910431e-01, 1.95709556e-01, 3.52968305e-01],\n",
       "       [8.67246985e-01, 7.97854215e-02, 2.16304716e-02, 3.13370787e-02],\n",
       "       [8.83971620e-03, 2.17205161e-05, 9.91119802e-01, 1.87890982e-05],\n",
       "       [9.29929540e-02, 1.11808581e-03, 9.04970527e-01, 9.18482547e-04],\n",
       "       [6.60496652e-01, 9.75495279e-02, 6.18824251e-02, 1.80071384e-01],\n",
       "       [1.97927132e-01, 3.16313282e-03, 7.88789153e-01, 1.01205669e-02],\n",
       "       [2.51340002e-01, 4.37588021e-02, 5.48090518e-01, 1.56810746e-01],\n",
       "       [4.80733544e-01, 4.54459488e-02, 7.85506144e-02, 3.95269871e-01],\n",
       "       [5.16137481e-01, 1.77482851e-02, 4.29047555e-01, 3.70666459e-02],\n",
       "       [6.11403286e-01, 1.32313535e-01, 1.58536851e-01, 9.77463722e-02],\n",
       "       [9.69338834e-01, 3.13924556e-03, 2.74174139e-02, 1.04491141e-04],\n",
       "       [5.92312515e-01, 1.47922248e-01, 1.68717504e-01, 9.10478234e-02],\n",
       "       [5.38305223e-01, 1.80298448e-01, 9.00402740e-02, 1.91356018e-01],\n",
       "       [1.28731966e-01, 6.03635684e-02, 8.10215652e-01, 6.88794884e-04],\n",
       "       [7.37818074e-04, 1.62277630e-07, 9.99261796e-01, 1.97491929e-07],\n",
       "       [2.06263468e-01, 1.12378143e-03, 7.89690733e-01, 2.92207603e-03],\n",
       "       [3.25679928e-01, 2.37600222e-01, 7.48789534e-02, 3.61840963e-01],\n",
       "       [4.02759433e-01, 1.33600771e-01, 4.09348942e-02, 4.22704935e-01],\n",
       "       [4.85551149e-01, 1.26550704e-01, 1.37095287e-01, 2.50802845e-01],\n",
       "       [8.85528252e-02, 5.04779769e-03, 8.89739037e-01, 1.66603010e-02],\n",
       "       [1.40247419e-01, 8.93558469e-03, 8.41936409e-01, 8.88063665e-03],\n",
       "       [3.84862558e-03, 2.07929952e-05, 9.96117353e-01, 1.33413687e-05],\n",
       "       [8.69678378e-01, 2.67953370e-02, 7.26058632e-02, 3.09204869e-02],\n",
       "       [1.58436466e-02, 9.01204294e-06, 9.84053671e-01, 9.36575743e-05],\n",
       "       [3.70883614e-01, 1.63607702e-01, 6.89016357e-02, 3.96607041e-01],\n",
       "       [5.67941666e-01, 2.35099271e-01, 1.16920017e-01, 8.00390840e-02],\n",
       "       [1.43086940e-01, 4.07517422e-03, 8.35566521e-01, 1.72713939e-02],\n",
       "       [4.39461023e-01, 3.11114802e-03, 5.56910753e-01, 5.17083681e-04],\n",
       "       [3.86741489e-01, 5.07660471e-02, 4.22623068e-01, 1.39869362e-01],\n",
       "       [5.55559024e-02, 4.86066751e-03, 9.37028587e-01, 2.55476823e-03],\n",
       "       [1.15546648e-08, 6.44425739e-08, 9.99999881e-01, 3.45687454e-13],\n",
       "       [2.69143462e-01, 6.28742622e-03, 6.08510571e-03, 7.18483984e-01],\n",
       "       [5.40907443e-01, 1.24622419e-01, 1.81376472e-01, 1.53093725e-01],\n",
       "       [2.52255195e-05, 7.85000623e-07, 9.99973893e-01, 2.82783930e-08],\n",
       "       [3.38761449e-01, 9.45922136e-02, 7.72828087e-02, 4.89363462e-01],\n",
       "       [3.48638475e-01, 1.73607264e-02, 6.06657386e-01, 2.73434464e-02],\n",
       "       [1.39282942e-01, 5.32671064e-03, 8.11055720e-01, 4.43347134e-02],\n",
       "       [9.20630336e-01, 6.50442624e-03, 3.75707587e-03, 6.91081285e-02],\n",
       "       [4.91596699e-01, 8.46737549e-02, 2.64579207e-01, 1.59150317e-01],\n",
       "       [1.39189319e-06, 8.49530082e-08, 9.99998450e-01, 1.01037982e-12],\n",
       "       [4.09068018e-01, 8.68413225e-02, 2.06864282e-01, 2.97226399e-01],\n",
       "       [3.24228436e-01, 5.54695278e-02, 5.23313105e-01, 9.69889462e-02],\n",
       "       [4.94307965e-01, 1.17162816e-01, 2.35610723e-01, 1.52918458e-01],\n",
       "       [1.01856003e-03, 3.91979711e-06, 7.11049142e-06, 9.98970389e-01],\n",
       "       [5.62543631e-01, 1.31719023e-01, 5.92711270e-02, 2.46466175e-01],\n",
       "       [1.47001475e-01, 4.82593803e-03, 6.64022982e-01, 1.84149668e-01],\n",
       "       [8.01020709e-04, 5.45158082e-06, 9.99190748e-01, 2.73215483e-06],\n",
       "       [4.08349484e-01, 3.91042233e-02, 3.58539909e-01, 1.94006398e-01],\n",
       "       [8.45413685e-01, 5.26971370e-02, 8.63097683e-02, 1.55793764e-02],\n",
       "       [3.83025348e-01, 1.94126695e-01, 6.83973804e-02, 3.54450613e-01],\n",
       "       [4.15993065e-01, 2.37472858e-02, 5.16017139e-01, 4.42425013e-02],\n",
       "       [2.00075775e-01, 4.46632179e-03, 7.92096972e-01, 3.36095528e-03],\n",
       "       [6.49175465e-01, 1.07747503e-01, 9.77591425e-02, 1.45317838e-01],\n",
       "       [3.26854885e-01, 9.87152383e-03, 4.43074226e-01, 2.20199421e-01],\n",
       "       [5.59015334e-01, 1.63671060e-03, 4.36270654e-01, 3.07727861e-03],\n",
       "       [9.41023529e-02, 3.09773465e-03, 8.96584928e-01, 6.21509226e-03],\n",
       "       [1.06361479e-01, 1.55750103e-02, 8.70423019e-01, 7.64046144e-03],\n",
       "       [5.53995132e-01, 1.29248634e-01, 2.08796576e-01, 1.07959606e-01],\n",
       "       [2.32556313e-01, 7.34294802e-02, 6.58318043e-01, 3.56960595e-02],\n",
       "       [2.14634433e-01, 7.61416135e-03, 7.62431264e-01, 1.53200775e-02],\n",
       "       [4.58305717e-01, 2.17142969e-01, 1.86091829e-02, 3.05942088e-01],\n",
       "       [9.55267027e-02, 2.58242362e-03, 8.93634975e-01, 8.25592969e-03],\n",
       "       [3.66210379e-02, 3.27373389e-04, 9.62677062e-01, 3.74469470e-04],\n",
       "       [3.23887110e-01, 1.33969665e-01, 4.95734334e-01, 4.64089587e-02],\n",
       "       [4.14316326e-01, 9.58053768e-03, 5.64050913e-01, 1.20522128e-02],\n",
       "       [1.51280954e-01, 9.13206767e-03, 8.23888898e-01, 1.56979915e-02],\n",
       "       [3.20474058e-01, 3.66996974e-03, 6.63377464e-01, 1.24785369e-02],\n",
       "       [2.37940699e-01, 8.62740725e-03, 7.22424924e-01, 3.10069472e-02],\n",
       "       [6.85728550e-01, 1.00907959e-01, 1.55871734e-01, 5.74916676e-02],\n",
       "       [7.16113925e-01, 2.91038137e-02, 2.45318234e-01, 9.46396124e-03],\n",
       "       [4.52127963e-01, 1.06748855e-02, 5.26991010e-01, 1.02061434e-02],\n",
       "       [4.28727537e-01, 1.29911080e-01, 2.06327572e-01, 2.35033855e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "650c4aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False,  True, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False, False,  True],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False,  True, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False,  True, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False, False,  True],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False,  True, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False,  True, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False, False,  True],\n",
       "       [False,  True, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False, False,  True],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False, False,  True],\n",
       "       [ True, False, False, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False],\n",
       "       [False, False, False,  True],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False,  True, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False, False,  True],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False, False,  True],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False,  True, False, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False, False,  True],\n",
       "       [False,  True, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False,  True, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False,  True, False]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9731510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "#compute confusion matrix\n",
    "conf_matrix = confusion_matrix(np.argmax(y_test, axis=1), y_pred_classes)\n",
    "\n",
    "#Plot confusion matrix\n",
    "sns.heatmap( conf_matrix, annot=True, fmt='d', cmap= 'Blues')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d00d66",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a87feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Male_Female_Healthy_Dataset/1004-a_n.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "334d7154",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(features_extraction(filename)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe4b49fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-182.332748</td>\n",
       "      <td>138.173431</td>\n",
       "      <td>-84.687096</td>\n",
       "      <td>10.047243</td>\n",
       "      <td>-48.317905</td>\n",
       "      <td>9.40225</td>\n",
       "      <td>2.296518</td>\n",
       "      <td>4.65991</td>\n",
       "      <td>-13.330125</td>\n",
       "      <td>9.432405</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.532734</td>\n",
       "      <td>1.599048</td>\n",
       "      <td>2.740876</td>\n",
       "      <td>-0.671063</td>\n",
       "      <td>1.497601</td>\n",
       "      <td>-0.059052</td>\n",
       "      <td>-2.493449</td>\n",
       "      <td>-0.113035</td>\n",
       "      <td>5.037437</td>\n",
       "      <td>-0.590547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1          2          3          4        5         6   \\\n",
       "0 -182.332748  138.173431 -84.687096  10.047243 -48.317905  9.40225  2.296518   \n",
       "\n",
       "        7          8         9   ...        70        71        72        73  \\\n",
       "0  4.65991 -13.330125  9.432405  ... -3.532734  1.599048  2.740876 -0.671063   \n",
       "\n",
       "         74        75        76        77        78        79  \n",
       "0  1.497601 -0.059052 -2.493449 -0.113035  5.037437 -0.590547  \n",
       "\n",
       "[1 rows x 80 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7cc1950",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(feature_df.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e27f65b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 80)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "516b73f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.36105075, 0.14097366, 0.17349696, 0.3244786 ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
