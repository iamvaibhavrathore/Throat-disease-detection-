{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b66bf280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de3e2d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7902e90f",
   "metadata": {},
   "source": [
    "## Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3758ffdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recording Id</th>\n",
       "      <th>Type</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diagnosis Notes</th>\n",
       "      <th>Pathology</th>\n",
       "      <th>Audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>22</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>4-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>22</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>5-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>25</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>9-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>23</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>11-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>24</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>15-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>58</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>29-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>45</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>32-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>40</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>20</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>40-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>41</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>20</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>41-a_n.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>43</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>32</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>43-a_n.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Recording Id Type Gender  Age Diagnosis Notes Pathology       Audio\n",
       "3              4    n      m   22          Normal    Normal   4-a_n.wav\n",
       "4              5    n      m   22          Normal    Normal   5-a_n.wav\n",
       "10             9    n      m   25          Normal    Normal   9-a_n.wav\n",
       "13            11    n      m   23          Normal    Normal  11-a_n.wav\n",
       "17            15    n      m   24          Normal    Normal  15-a_n.wav\n",
       "29            29    n      m   58          Normal    Normal  29-a_n.wav\n",
       "32            32    n      m   45          Normal    Normal  32-a_n.wav\n",
       "41            40    n      m   20          Normal    Normal  40-a_n.wav\n",
       "42            41    n      m   20          Normal    Normal  41-a_n.wav\n",
       "44            43    n      m   32          Normal    Normal  43-a_n.wav"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1=pd.read_excel('Healthy_data.xlsx')\n",
    "df2=pd.read_excel('Pathological_data.xlsx')\n",
    "df=pd.concat([df1,df2], ignore_index=True)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5fe054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(561, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76cfc7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 561 entries, 3 to 1358\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Recording Id     561 non-null    int64 \n",
      " 1   Type             561 non-null    object\n",
      " 2   Gender           561 non-null    object\n",
      " 3   Age              561 non-null    int64 \n",
      " 4   Diagnosis Notes  534 non-null    object\n",
      " 5   Pathology        561 non-null    object\n",
      " 6   Audio            561 non-null    object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 35.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1020f8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Audio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <th>m</th>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <th>m</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Audio\n",
       "Type Gender       \n",
       "n    m         259\n",
       "p    m         302"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_gender_count = df.groupby([\"Type\",\"Gender\"])[['Audio']].count()\n",
    "type_gender_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d9f69cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Type,Gender'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type_gender_count.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1a14c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m']\n",
      "['Normal' 'Dysphonia' 'Laryngitis' 'Recurrent palsy']\n"
     ]
    }
   ],
   "source": [
    "gender = df.Gender.unique()\n",
    "pathology = df.Pathology.unique()\n",
    "print(gender)\n",
    "print(pathology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98636eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=df[\"Pathology\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59c7019",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff680d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting MFCC's for every audio file\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "audio_dataset_path = 'Filtered_Audio_Dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa9d6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extraction(file):\n",
    "    audio, sample_rate = librosa.load(file_name)\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, n_mfcc=80)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "722e8c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "561it [00:05, 106.67it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(df.iterrows()):\n",
    "    file_name = audio_dataset_path+row[\"Audio\"]\n",
    "    final_class_labels = row[\"Type\"]\n",
    "    data = features_extraction(file_name)\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c814f35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-279.40063, 208.5046, -43.03498, -5.360972, -...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-172.24774, 175.08725, -75.93269, 8.99103, -6...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-160.34767, 238.37305, -50.651237, -8.1686945...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-174.26558, 202.43498, -48.88869, 26.138357, ...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-178.27687, 191.5492, -72.10441, 7.839301, -4...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-197.26646, 189.61101, -47.13572, 9.000772, -...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[-228.07176, 183.02597, -31.626911, -15.123821...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[-235.79805, 207.87103, -39.370472, -27.216578...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-332.56256, 205.95406, -61.05219, 7.6796494, ...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[-147.25772, 178.20045, -82.12582, 1.9781523, ...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature class\n",
       "0  [-279.40063, 208.5046, -43.03498, -5.360972, -...     n\n",
       "1  [-172.24774, 175.08725, -75.93269, 8.99103, -6...     n\n",
       "2  [-160.34767, 238.37305, -50.651237, -8.1686945...     n\n",
       "3  [-174.26558, 202.43498, -48.88869, 26.138357, ...     n\n",
       "4  [-178.27687, 191.5492, -72.10441, 7.839301, -4...     n\n",
       "5  [-197.26646, 189.61101, -47.13572, 9.000772, -...     n\n",
       "6  [-228.07176, 183.02597, -31.626911, -15.123821...     n\n",
       "7  [-235.79805, 207.87103, -39.370472, -27.216578...     n\n",
       "8  [-332.56256, 205.95406, -61.05219, 7.6796494, ...     n\n",
       "9  [-147.25772, 178.20045, -82.12582, 1.9781523, ...     n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df = pd.DataFrame(extracted_features, columns=['feature','class'])\n",
    "extracted_features_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2827c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(561, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bb09498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.7940063e+02,  2.0850459e+02, -4.3034981e+01, -5.3609719e+00,\n",
       "       -5.2530403e+01, -8.8619261e+00, -7.6732415e-01,  6.7943349e+00,\n",
       "        1.0799702e+01, -1.3331823e+00,  8.6732759e+00, -7.2678752e+00,\n",
       "        1.8010962e+01,  1.9159014e+01, -2.7179031e+01, -1.2447955e+01,\n",
       "        1.8915423e+00, -1.5298142e+01, -4.0988545e+00,  1.8953447e+00,\n",
       "        4.7810760e+00, -3.4840662e+00, -1.6979162e+01, -3.4267972e+00,\n",
       "        4.2249260e+00, -9.3542862e+00, -7.8552189e+00, -2.2184309e-01,\n",
       "       -7.5720377e+00, -6.0218911e+00, -9.1817122e+00,  6.1179090e+00,\n",
       "        4.7846541e+00, -8.6046515e+00,  1.2105453e+01, -1.6410214e+00,\n",
       "       -9.7464371e+00,  3.2591763e+00, -8.6933661e+00, -5.1998725e+00,\n",
       "        3.8980737e+00, -7.4412656e+00, -5.7363014e+00, -3.9971590e+00,\n",
       "       -6.7316098e+00, -3.1640453e+00, -6.6905761e+00, -3.9208169e+00,\n",
       "       -3.4986355e+00, -3.5767493e+00, -3.5865269e+00, -6.1424880e+00,\n",
       "       -8.7377186e+00, -6.3181624e+00, -2.7753470e+00, -4.7034574e+00,\n",
       "        1.1015921e-01, -5.1750245e+00, -5.6951485e+00, -1.7120453e+00,\n",
       "       -7.7000837e+00, -1.0622505e+01, -1.0383512e+01, -7.7237840e+00,\n",
       "        2.5946653e+00,  1.8232792e+01,  2.4936136e+01,  2.8669571e+01,\n",
       "        2.2835281e+01,  1.0904361e+01,  4.4246721e+00,  2.5350792e+00,\n",
       "        3.3170602e+00,  5.7518373e+00,  7.4122915e+00,  1.1257874e+00,\n",
       "       -1.8074751e+00, -2.9770665e+00,  1.7964569e+00,  3.8540685e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df[\"feature\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85fff3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label Encoding\n",
    "dummy_data = pd.get_dummies(extracted_features_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4758d3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>561 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         n      p\n",
       "0     True  False\n",
       "1     True  False\n",
       "2     True  False\n",
       "3     True  False\n",
       "4     True  False\n",
       "..     ...    ...\n",
       "556  False   True\n",
       "557  False   True\n",
       "558  False   True\n",
       "559  False   True\n",
       "560  False   True\n",
       "\n",
       "[561 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b543b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(extracted_features_df['feature'].values.tolist())\n",
    "y=dummy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "302d1f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(561, 80)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faca9110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(561, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7262660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,stratify= y, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e1d6d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448, 80)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81e0a1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 80)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70ec852f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48321029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff207eb",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d59d97d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3c49c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0586ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## No. of classes\n",
    "num_labels=y.shape[1]\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06adc7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "## first layer\n",
    "model.add(Dense(256,input_shape=(80,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "## second layer\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "## third layer\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "## final Layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e79dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94095501",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               20736     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 219138 (856.01 KB)\n",
      "Trainable params: 219138 (856.01 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "727a1c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 13.7816 - accuracy: 0.4974 \n",
      "Epoch 1: val_loss improved from inf to 1.87221, saving model to /audio_classification.hdf5\n",
      "14/14 [==============================] - 2s 76ms/step - loss: 13.1477 - accuracy: 0.5022 - val_loss: 1.8722 - val_accuracy: 0.5575\n",
      "Epoch 2/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 7.7492 - accuracy: 0.5357\n",
      "Epoch 2: val_loss did not improve from 1.87221\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 7.7492 - accuracy: 0.5357 - val_loss: 2.6637 - val_accuracy: 0.4602\n",
      "Epoch 3/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 5.7355 - accuracy: 0.5168"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: val_loss improved from 1.87221 to 0.97935, saving model to /audio_classification.hdf5\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 5.7299 - accuracy: 0.5134 - val_loss: 0.9793 - val_accuracy: 0.6018\n",
      "Epoch 4/150\n",
      " 5/14 [=========>....................] - ETA: 0s - loss: 4.9261 - accuracy: 0.5750\n",
      "Epoch 4: val_loss did not improve from 0.97935\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 4.9483 - accuracy: 0.5848 - val_loss: 1.4213 - val_accuracy: 0.5841\n",
      "Epoch 5/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 5.4313 - accuracy: 0.5312\n",
      "Epoch 5: val_loss improved from 0.97935 to 0.78608, saving model to /audio_classification.hdf5\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 4.4024 - accuracy: 0.5022 - val_loss: 0.7861 - val_accuracy: 0.5752\n",
      "Epoch 6/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 3.5916 - accuracy: 0.5625\n",
      "Epoch 6: val_loss improved from 0.78608 to 0.66937, saving model to /audio_classification.hdf5\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 3.2654 - accuracy: 0.5045 - val_loss: 0.6694 - val_accuracy: 0.6372\n",
      "Epoch 7/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 3.2070 - accuracy: 0.4375\n",
      "Epoch 7: val_loss improved from 0.66937 to 0.62850, saving model to /audio_classification.hdf5\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 2.2829 - accuracy: 0.5603 - val_loss: 0.6285 - val_accuracy: 0.6903\n",
      "Epoch 8/150\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 2.4528 - accuracy: 0.5417\n",
      "Epoch 8: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.5597 - accuracy: 0.5290 - val_loss: 0.6299 - val_accuracy: 0.6460\n",
      "Epoch 9/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 2.0798 - accuracy: 0.5558\n",
      "Epoch 9: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.0798 - accuracy: 0.5558 - val_loss: 0.6312 - val_accuracy: 0.6195\n",
      "Epoch 10/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.5278 - accuracy: 0.5697\n",
      "Epoch 10: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5399 - accuracy: 0.5692 - val_loss: 0.6687 - val_accuracy: 0.6018\n",
      "Epoch 11/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 2.1613 - accuracy: 0.5625\n",
      "Epoch 11: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5673 - accuracy: 0.5826 - val_loss: 0.6434 - val_accuracy: 0.6372\n",
      "Epoch 12/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.4277 - accuracy: 0.5536\n",
      "Epoch 12: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.4277 - accuracy: 0.5536 - val_loss: 0.6357 - val_accuracy: 0.6283\n",
      "Epoch 13/150\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 1.3432 - accuracy: 0.5885\n",
      "Epoch 13: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.4234 - accuracy: 0.5781 - val_loss: 0.6453 - val_accuracy: 0.6283\n",
      "Epoch 14/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.1024 - accuracy: 0.7188\n",
      "Epoch 14: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.3185 - accuracy: 0.5826 - val_loss: 0.6733 - val_accuracy: 0.5841\n",
      "Epoch 15/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7943 - accuracy: 0.6562\n",
      "Epoch 15: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.1939 - accuracy: 0.5625 - val_loss: 0.6668 - val_accuracy: 0.5487\n",
      "Epoch 16/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.2100 - accuracy: 0.5938\n",
      "Epoch 16: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.1504 - accuracy: 0.6138 - val_loss: 0.6691 - val_accuracy: 0.5221\n",
      "Epoch 17/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.0251 - accuracy: 0.5312\n",
      "Epoch 17: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.1458 - accuracy: 0.5625 - val_loss: 0.6676 - val_accuracy: 0.6018\n",
      "Epoch 18/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.1854 - accuracy: 0.5625\n",
      "Epoch 18: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.1854 - accuracy: 0.5625 - val_loss: 0.6627 - val_accuracy: 0.6018\n",
      "Epoch 19/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.4199 - accuracy: 0.5000\n",
      "Epoch 19: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.0907 - accuracy: 0.5625 - val_loss: 0.6635 - val_accuracy: 0.5752\n",
      "Epoch 20/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0241 - accuracy: 0.5402\n",
      "Epoch 20: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.0241 - accuracy: 0.5402 - val_loss: 0.6638 - val_accuracy: 0.5575\n",
      "Epoch 21/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.9550 - accuracy: 0.5312\n",
      "Epoch 21: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.9546 - accuracy: 0.5871 - val_loss: 0.6657 - val_accuracy: 0.5487\n",
      "Epoch 22/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.0894 - accuracy: 0.5625\n",
      "Epoch 22: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.9021 - accuracy: 0.5938 - val_loss: 0.6619 - val_accuracy: 0.6106\n",
      "Epoch 23/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.8727 - accuracy: 0.6562\n",
      "Epoch 23: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.8242 - accuracy: 0.6317 - val_loss: 0.6603 - val_accuracy: 0.5841\n",
      "Epoch 24/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.8095 - accuracy: 0.5938\n",
      "Epoch 24: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.9144 - accuracy: 0.5848 - val_loss: 0.6577 - val_accuracy: 0.5929\n",
      "Epoch 25/150\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.8924 - accuracy: 0.6007\n",
      "Epoch 25: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.9026 - accuracy: 0.5915 - val_loss: 0.6640 - val_accuracy: 0.6018\n",
      "Epoch 26/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7251 - accuracy: 0.5000\n",
      "Epoch 26: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.8414 - accuracy: 0.5804 - val_loss: 0.6597 - val_accuracy: 0.6460\n",
      "Epoch 27/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7690 - accuracy: 0.5312\n",
      "Epoch 27: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.8124 - accuracy: 0.5781 - val_loss: 0.6394 - val_accuracy: 0.6549\n",
      "Epoch 28/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7476 - accuracy: 0.6250\n",
      "Epoch 28: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.7906 - accuracy: 0.5982 - val_loss: 0.6399 - val_accuracy: 0.6549\n",
      "Epoch 29/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.8449 - accuracy: 0.5625\n",
      "Epoch 29: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.7447 - accuracy: 0.6295 - val_loss: 0.6449 - val_accuracy: 0.6372\n",
      "Epoch 30/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.8472 - accuracy: 0.5312\n",
      "Epoch 30: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.7794 - accuracy: 0.5759 - val_loss: 0.6476 - val_accuracy: 0.6283\n",
      "Epoch 31/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6685 - accuracy: 0.6875\n",
      "Epoch 31: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.7571 - accuracy: 0.6250 - val_loss: 0.6360 - val_accuracy: 0.6283\n",
      "Epoch 32/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7158 - accuracy: 0.6154\n",
      "Epoch 32: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.7008 - accuracy: 0.6228 - val_loss: 0.6379 - val_accuracy: 0.6814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7155 - accuracy: 0.6384\n",
      "Epoch 33: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.7155 - accuracy: 0.6384 - val_loss: 0.6334 - val_accuracy: 0.6814\n",
      "Epoch 34/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6881 - accuracy: 0.6451\n",
      "Epoch 34: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6881 - accuracy: 0.6451 - val_loss: 0.6393 - val_accuracy: 0.6460\n",
      "Epoch 35/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7399 - accuracy: 0.6875\n",
      "Epoch 35: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.7552 - accuracy: 0.6183 - val_loss: 0.6458 - val_accuracy: 0.6106\n",
      "Epoch 36/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6638 - accuracy: 0.6875\n",
      "Epoch 36: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.7169 - accuracy: 0.6250 - val_loss: 0.6425 - val_accuracy: 0.6372\n",
      "Epoch 37/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.8621 - accuracy: 0.5938\n",
      "Epoch 37: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6898 - accuracy: 0.6384 - val_loss: 0.6294 - val_accuracy: 0.6372\n",
      "Epoch 38/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4972 - accuracy: 0.7500\n",
      "Epoch 38: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6748 - accuracy: 0.6518 - val_loss: 0.6327 - val_accuracy: 0.6637\n",
      "Epoch 39/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6189 - accuracy: 0.6250\n",
      "Epoch 39: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6423 - accuracy: 0.6607 - val_loss: 0.6374 - val_accuracy: 0.6460\n",
      "Epoch 40/150\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.6728 - accuracy: 0.6406\n",
      "Epoch 40: val_loss did not improve from 0.62850\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.6679 - accuracy: 0.6429 - val_loss: 0.6285 - val_accuracy: 0.6283\n",
      "Epoch 41/150\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.7002 - accuracy: 0.6380\n",
      "Epoch 41: val_loss improved from 0.62850 to 0.62255, saving model to /audio_classification.hdf5\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.6938 - accuracy: 0.6295 - val_loss: 0.6226 - val_accuracy: 0.6726\n",
      "Epoch 42/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5941 - accuracy: 0.8125\n",
      "Epoch 42: val_loss improved from 0.62255 to 0.61391, saving model to /audio_classification.hdf5\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6607 - val_loss: 0.6139 - val_accuracy: 0.6372\n",
      "Epoch 43/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6616 - accuracy: 0.6899\n",
      "Epoch 43: val_loss improved from 0.61391 to 0.60860, saving model to /audio_classification.hdf5\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.6468 - accuracy: 0.6920 - val_loss: 0.6086 - val_accuracy: 0.6814\n",
      "Epoch 44/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6994 - accuracy: 0.6562\n",
      "Epoch 44: val_loss improved from 0.60860 to 0.60667, saving model to /audio_classification.hdf5\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6250 - accuracy: 0.6585 - val_loss: 0.6067 - val_accuracy: 0.6814\n",
      "Epoch 45/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5410 - accuracy: 0.7500\n",
      "Epoch 45: val_loss improved from 0.60667 to 0.60214, saving model to /audio_classification.hdf5\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6303 - accuracy: 0.6652 - val_loss: 0.6021 - val_accuracy: 0.6372\n",
      "Epoch 46/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6278 - accuracy: 0.6496\n",
      "Epoch 46: val_loss improved from 0.60214 to 0.59933, saving model to /audio_classification.hdf5\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.6278 - accuracy: 0.6496 - val_loss: 0.5993 - val_accuracy: 0.6814\n",
      "Epoch 47/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6153 - accuracy: 0.6779\n",
      "Epoch 47: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.6132 - accuracy: 0.6808 - val_loss: 0.6011 - val_accuracy: 0.6814\n",
      "Epoch 48/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5935 - accuracy: 0.7091\n",
      "Epoch 48: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5965 - accuracy: 0.7031 - val_loss: 0.6088 - val_accuracy: 0.6903\n",
      "Epoch 49/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4160 - accuracy: 0.8125\n",
      "Epoch 49: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5858 - accuracy: 0.6875 - val_loss: 0.6085 - val_accuracy: 0.6726\n",
      "Epoch 50/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5807 - accuracy: 0.6562\n",
      "Epoch 50: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6093 - accuracy: 0.6741 - val_loss: 0.6082 - val_accuracy: 0.6903\n",
      "Epoch 51/150\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.6754 - accuracy: 0.6406\n",
      "Epoch 51: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.6519 - accuracy: 0.6629 - val_loss: 0.6104 - val_accuracy: 0.6637\n",
      "Epoch 52/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5318 - accuracy: 0.8438\n",
      "Epoch 52: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6117 - accuracy: 0.6875 - val_loss: 0.6191 - val_accuracy: 0.6637\n",
      "Epoch 53/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5112 - accuracy: 0.7500\n",
      "Epoch 53: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5730 - accuracy: 0.6942 - val_loss: 0.6150 - val_accuracy: 0.6460\n",
      "Epoch 54/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4627 - accuracy: 0.7500\n",
      "Epoch 54: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5839 - accuracy: 0.6607 - val_loss: 0.6201 - val_accuracy: 0.6637\n",
      "Epoch 55/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4342 - accuracy: 0.7188\n",
      "Epoch 55: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5500 - accuracy: 0.6987 - val_loss: 0.6174 - val_accuracy: 0.6460\n",
      "Epoch 56/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4177 - accuracy: 0.9062\n",
      "Epoch 56: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5666 - accuracy: 0.7165 - val_loss: 0.6125 - val_accuracy: 0.6814\n",
      "Epoch 57/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6465 - accuracy: 0.6562\n",
      "Epoch 57: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5642 - accuracy: 0.7210 - val_loss: 0.6107 - val_accuracy: 0.6991\n",
      "Epoch 58/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5776 - accuracy: 0.7812\n",
      "Epoch 58: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5635 - accuracy: 0.7031 - val_loss: 0.6113 - val_accuracy: 0.7080\n",
      "Epoch 59/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5881 - accuracy: 0.6947\n",
      "Epoch 59: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.5775 - accuracy: 0.7031 - val_loss: 0.6057 - val_accuracy: 0.6814\n",
      "Epoch 60/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6263 - accuracy: 0.6875\n",
      "Epoch 60: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5506 - accuracy: 0.6853 - val_loss: 0.6014 - val_accuracy: 0.6726\n",
      "Epoch 61/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5547 - accuracy: 0.6562\n",
      "Epoch 61: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5230 - accuracy: 0.7143 - val_loss: 0.6089 - val_accuracy: 0.6726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5349 - accuracy: 0.7260\n",
      "Epoch 62: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.5390 - accuracy: 0.7277 - val_loss: 0.6117 - val_accuracy: 0.6372\n",
      "Epoch 63/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5112 - accuracy: 0.7163\n",
      "Epoch 63: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.5218 - accuracy: 0.7121 - val_loss: 0.6115 - val_accuracy: 0.6460\n",
      "Epoch 64/150\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.4857 - accuracy: 0.7604\n",
      "Epoch 64: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4824 - accuracy: 0.7634 - val_loss: 0.6178 - val_accuracy: 0.6549\n",
      "Epoch 65/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5369 - accuracy: 0.6562\n",
      "Epoch 65: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4762 - accuracy: 0.7344 - val_loss: 0.6251 - val_accuracy: 0.6726\n",
      "Epoch 66/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4345 - accuracy: 0.8125\n",
      "Epoch 66: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4840 - accuracy: 0.7723 - val_loss: 0.6201 - val_accuracy: 0.6637\n",
      "Epoch 67/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.4670 - accuracy: 0.7452\n",
      "Epoch 67: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4621 - accuracy: 0.7500 - val_loss: 0.6124 - val_accuracy: 0.6549\n",
      "Epoch 68/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4464 - accuracy: 0.7500\n",
      "Epoch 68: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4459 - accuracy: 0.7746 - val_loss: 0.6123 - val_accuracy: 0.6814\n",
      "Epoch 69/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4699 - accuracy: 0.7545\n",
      "Epoch 69: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4699 - accuracy: 0.7545 - val_loss: 0.6106 - val_accuracy: 0.6549\n",
      "Epoch 70/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4433 - accuracy: 0.8125\n",
      "Epoch 70: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5007 - accuracy: 0.7478 - val_loss: 0.6214 - val_accuracy: 0.6637\n",
      "Epoch 71/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.4935 - accuracy: 0.7524\n",
      "Epoch 71: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4933 - accuracy: 0.7500 - val_loss: 0.6298 - val_accuracy: 0.6726\n",
      "Epoch 72/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.4816 - accuracy: 0.7596\n",
      "Epoch 72: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4737 - accuracy: 0.7612 - val_loss: 0.6216 - val_accuracy: 0.6637\n",
      "Epoch 73/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3956 - accuracy: 0.8438\n",
      "Epoch 73: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4968 - accuracy: 0.7411 - val_loss: 0.6111 - val_accuracy: 0.6991\n",
      "Epoch 74/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4613 - accuracy: 0.7188\n",
      "Epoch 74: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.7701 - val_loss: 0.6126 - val_accuracy: 0.6726\n",
      "Epoch 75/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4841 - accuracy: 0.7188\n",
      "Epoch 75: val_loss did not improve from 0.59933\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7411 - val_loss: 0.6102 - val_accuracy: 0.6637\n",
      "Epoch 76/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4823 - accuracy: 0.8438\n",
      "Epoch 76: val_loss improved from 0.59933 to 0.59855, saving model to /audio_classification.hdf5\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.4531 - accuracy: 0.7768 - val_loss: 0.5986 - val_accuracy: 0.6814\n",
      "Epoch 77/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4527 - accuracy: 0.7500\n",
      "Epoch 77: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4725 - accuracy: 0.7545 - val_loss: 0.6007 - val_accuracy: 0.7080\n",
      "Epoch 78/150\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.4624 - accuracy: 0.7708\n",
      "Epoch 78: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4596 - accuracy: 0.7723 - val_loss: 0.6102 - val_accuracy: 0.6814\n",
      "Epoch 79/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4611 - accuracy: 0.7701\n",
      "Epoch 79: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4611 - accuracy: 0.7701 - val_loss: 0.6125 - val_accuracy: 0.6814\n",
      "Epoch 80/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4338 - accuracy: 0.7902\n",
      "Epoch 80: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4338 - accuracy: 0.7902 - val_loss: 0.6178 - val_accuracy: 0.6903\n",
      "Epoch 81/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.4168 - accuracy: 0.8125\n",
      "Epoch 81: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4161 - accuracy: 0.8080 - val_loss: 0.6219 - val_accuracy: 0.6903\n",
      "Epoch 82/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4684 - accuracy: 0.8125\n",
      "Epoch 82: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7835 - val_loss: 0.6319 - val_accuracy: 0.6726\n",
      "Epoch 83/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.4332 - accuracy: 0.7909\n",
      "Epoch 83: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4498 - accuracy: 0.7790 - val_loss: 0.6324 - val_accuracy: 0.6549\n",
      "Epoch 84/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.4379 - accuracy: 0.8005\n",
      "Epoch 84: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4513 - accuracy: 0.7946 - val_loss: 0.6575 - val_accuracy: 0.6726\n",
      "Epoch 85/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5114 - accuracy: 0.7500\n",
      "Epoch 85: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4377 - accuracy: 0.7746 - val_loss: 0.6367 - val_accuracy: 0.6549\n",
      "Epoch 86/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4108 - accuracy: 0.8036\n",
      "Epoch 86: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8036 - val_loss: 0.6295 - val_accuracy: 0.6549\n",
      "Epoch 87/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3845 - accuracy: 0.8125\n",
      "Epoch 87: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3845 - accuracy: 0.8125 - val_loss: 0.6487 - val_accuracy: 0.6637\n",
      "Epoch 88/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4176 - accuracy: 0.7812\n",
      "Epoch 88: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.7946 - val_loss: 0.6627 - val_accuracy: 0.6637\n",
      "Epoch 89/150\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.4171 - accuracy: 0.8164\n",
      "Epoch 89: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4160 - accuracy: 0.8058 - val_loss: 0.6639 - val_accuracy: 0.6637\n",
      "Epoch 90/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2714 - accuracy: 0.8125\n",
      "Epoch 90: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3888 - accuracy: 0.8214 - val_loss: 0.6797 - val_accuracy: 0.6903\n",
      "Epoch 91/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1714 - accuracy: 1.0000\n",
      "Epoch 91: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3499 - accuracy: 0.8594 - val_loss: 0.6833 - val_accuracy: 0.6903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/150\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.3776 - accuracy: 0.8125\n",
      "Epoch 92: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.3670 - accuracy: 0.8214 - val_loss: 0.6856 - val_accuracy: 0.6991\n",
      "Epoch 93/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3138 - accuracy: 0.9375\n",
      "Epoch 93: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3197 - accuracy: 0.8616 - val_loss: 0.6722 - val_accuracy: 0.6726\n",
      "Epoch 94/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.3497 - accuracy: 0.8438\n",
      "Epoch 94: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.3476 - accuracy: 0.8460 - val_loss: 0.6908 - val_accuracy: 0.6549\n",
      "Epoch 95/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3422 - accuracy: 0.8616\n",
      "Epoch 95: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3422 - accuracy: 0.8616 - val_loss: 0.6821 - val_accuracy: 0.6903\n",
      "Epoch 96/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2962 - accuracy: 0.8125\n",
      "Epoch 96: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3465 - accuracy: 0.8438 - val_loss: 0.6857 - val_accuracy: 0.6637\n",
      "Epoch 97/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2431 - accuracy: 0.8750\n",
      "Epoch 97: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.8170 - val_loss: 0.7020 - val_accuracy: 0.6726\n",
      "Epoch 98/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3175 - accuracy: 0.8504\n",
      "Epoch 98: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3175 - accuracy: 0.8504 - val_loss: 0.7022 - val_accuracy: 0.6549\n",
      "Epoch 99/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2050 - accuracy: 0.9375\n",
      "Epoch 99: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2927 - accuracy: 0.8839 - val_loss: 0.7287 - val_accuracy: 0.6726\n",
      "Epoch 100/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2814 - accuracy: 0.8750\n",
      "Epoch 100: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3258 - accuracy: 0.8371 - val_loss: 0.7331 - val_accuracy: 0.6903\n",
      "Epoch 101/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3159 - accuracy: 0.8125\n",
      "Epoch 101: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3151 - accuracy: 0.8527 - val_loss: 0.7349 - val_accuracy: 0.6637\n",
      "Epoch 102/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0967 - accuracy: 1.0000\n",
      "Epoch 102: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3231 - accuracy: 0.8594 - val_loss: 0.7179 - val_accuracy: 0.6726\n",
      "Epoch 103/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5835 - accuracy: 0.6875\n",
      "Epoch 103: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3278 - accuracy: 0.8460 - val_loss: 0.7286 - val_accuracy: 0.6549\n",
      "Epoch 104/150\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.3047 - accuracy: 0.8672\n",
      "Epoch 104: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.2970 - accuracy: 0.8683 - val_loss: 0.7668 - val_accuracy: 0.6460\n",
      "Epoch 105/150\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2862 - accuracy: 0.8750\n",
      "Epoch 105: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.2747 - accuracy: 0.8795 - val_loss: 0.7848 - val_accuracy: 0.6549\n",
      "Epoch 106/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2593 - accuracy: 0.8750\n",
      "Epoch 106: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2664 - accuracy: 0.8795 - val_loss: 0.7854 - val_accuracy: 0.6726\n",
      "Epoch 107/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3596 - accuracy: 0.8438\n",
      "Epoch 107: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2857 - accuracy: 0.8705 - val_loss: 0.8156 - val_accuracy: 0.6814\n",
      "Epoch 108/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1958 - accuracy: 0.9062\n",
      "Epoch 108: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2435 - accuracy: 0.9040 - val_loss: 0.8635 - val_accuracy: 0.6814\n",
      "Epoch 109/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1963 - accuracy: 0.8750\n",
      "Epoch 109: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2725 - accuracy: 0.8728 - val_loss: 0.8637 - val_accuracy: 0.6460\n",
      "Epoch 110/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2587 - accuracy: 0.8929\n",
      "Epoch 110: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2587 - accuracy: 0.8929 - val_loss: 0.8448 - val_accuracy: 0.6726\n",
      "Epoch 111/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3766 - accuracy: 0.7812\n",
      "Epoch 111: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2564 - accuracy: 0.8795 - val_loss: 0.8417 - val_accuracy: 0.6637\n",
      "Epoch 112/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.9062\n",
      "Epoch 112: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2344 - accuracy: 0.9062 - val_loss: 0.8361 - val_accuracy: 0.6637\n",
      "Epoch 113/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1557 - accuracy: 0.9688\n",
      "Epoch 113: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2330 - accuracy: 0.8951 - val_loss: 0.8488 - val_accuracy: 0.6991\n",
      "Epoch 114/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4704 - accuracy: 0.7500\n",
      "Epoch 114: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2588 - accuracy: 0.8661 - val_loss: 0.8558 - val_accuracy: 0.6549\n",
      "Epoch 115/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2383 - accuracy: 0.9018\n",
      "Epoch 115: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2383 - accuracy: 0.9018 - val_loss: 0.8829 - val_accuracy: 0.6903\n",
      "Epoch 116/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1088 - accuracy: 0.9688\n",
      "Epoch 116: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2086 - accuracy: 0.8951 - val_loss: 0.9517 - val_accuracy: 0.6460\n",
      "Epoch 117/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2342 - accuracy: 0.9062\n",
      "Epoch 117: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2204 - accuracy: 0.9062 - val_loss: 0.8834 - val_accuracy: 0.6903\n",
      "Epoch 118/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2272 - accuracy: 0.8973\n",
      "Epoch 118: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2272 - accuracy: 0.8973 - val_loss: 0.9794 - val_accuracy: 0.6903\n",
      "Epoch 119/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1491 - accuracy: 0.9375\n",
      "Epoch 119: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2087 - accuracy: 0.9308 - val_loss: 0.9430 - val_accuracy: 0.6637\n",
      "Epoch 120/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1133 - accuracy: 1.0000\n",
      "Epoch 120: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1873 - accuracy: 0.9152 - val_loss: 0.9588 - val_accuracy: 0.6372\n",
      "Epoch 121/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2103 - accuracy: 0.9107\n",
      "Epoch 121: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2103 - accuracy: 0.9107 - val_loss: 1.0290 - val_accuracy: 0.6460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2609 - accuracy: 0.8438\n",
      "Epoch 122: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1841 - accuracy: 0.9196 - val_loss: 1.0537 - val_accuracy: 0.6549\n",
      "Epoch 123/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1417 - accuracy: 0.9375\n",
      "Epoch 123: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1518 - accuracy: 0.9397 - val_loss: 1.0042 - val_accuracy: 0.6549\n",
      "Epoch 124/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.9442\n",
      "Epoch 124: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1509 - accuracy: 0.9442 - val_loss: 1.0432 - val_accuracy: 0.6549\n",
      "Epoch 125/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1969 - accuracy: 0.9062\n",
      "Epoch 125: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1800 - accuracy: 0.9375 - val_loss: 1.1375 - val_accuracy: 0.6283\n",
      "Epoch 126/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1651 - accuracy: 0.9231\n",
      "Epoch 126: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1683 - accuracy: 0.9263 - val_loss: 1.1694 - val_accuracy: 0.6372\n",
      "Epoch 127/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1821 - accuracy: 0.9062\n",
      "Epoch 127: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2238 - accuracy: 0.9152 - val_loss: 1.1481 - val_accuracy: 0.6283\n",
      "Epoch 128/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1773 - accuracy: 0.9375\n",
      "Epoch 128: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2003 - accuracy: 0.9152 - val_loss: 1.0280 - val_accuracy: 0.6549\n",
      "Epoch 129/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1972 - accuracy: 0.9062\n",
      "Epoch 129: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1824 - accuracy: 0.9263 - val_loss: 1.0836 - val_accuracy: 0.6283\n",
      "Epoch 130/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3188 - accuracy: 0.9062\n",
      "Epoch 130: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1659 - accuracy: 0.9330 - val_loss: 1.1268 - val_accuracy: 0.6549\n",
      "Epoch 131/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1543 - accuracy: 0.9375\n",
      "Epoch 131: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1704 - accuracy: 0.9174 - val_loss: 1.1511 - val_accuracy: 0.6726\n",
      "Epoch 132/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1571 - accuracy: 0.9327\n",
      "Epoch 132: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1633 - accuracy: 0.9330 - val_loss: 1.1274 - val_accuracy: 0.6814\n",
      "Epoch 133/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0420 - accuracy: 1.0000\n",
      "Epoch 133: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1627 - accuracy: 0.9420 - val_loss: 1.0514 - val_accuracy: 0.6460\n",
      "Epoch 134/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1859 - accuracy: 0.8750\n",
      "Epoch 134: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1656 - accuracy: 0.9196 - val_loss: 1.1030 - val_accuracy: 0.6372\n",
      "Epoch 135/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1803 - accuracy: 0.9255\n",
      "Epoch 135: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1704 - accuracy: 0.9308 - val_loss: 1.1212 - val_accuracy: 0.6726\n",
      "Epoch 136/150\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.1337 - accuracy: 0.9567\n",
      "Epoch 136: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1379 - accuracy: 0.9531 - val_loss: 1.1204 - val_accuracy: 0.6726\n",
      "Epoch 137/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0517 - accuracy: 1.0000\n",
      "Epoch 137: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1203 - accuracy: 0.9464 - val_loss: 1.2103 - val_accuracy: 0.6637\n",
      "Epoch 138/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9531\n",
      "Epoch 138: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1045 - accuracy: 0.9531 - val_loss: 1.2254 - val_accuracy: 0.6726\n",
      "Epoch 139/150\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.1274 - accuracy: 0.9427\n",
      "Epoch 139: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1125 - accuracy: 0.9487 - val_loss: 1.2914 - val_accuracy: 0.6549\n",
      "Epoch 140/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1217 - accuracy: 0.9576\n",
      "Epoch 140: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1217 - accuracy: 0.9576 - val_loss: 1.2547 - val_accuracy: 0.6372\n",
      "Epoch 141/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1371 - accuracy: 0.9688\n",
      "Epoch 141: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1209 - accuracy: 0.9531 - val_loss: 1.3154 - val_accuracy: 0.6814\n",
      "Epoch 142/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.9598\n",
      "Epoch 142: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1154 - accuracy: 0.9598 - val_loss: 1.3286 - val_accuracy: 0.6726\n",
      "Epoch 143/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1462 - accuracy: 0.8750\n",
      "Epoch 143: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1617 - accuracy: 0.9375 - val_loss: 1.3148 - val_accuracy: 0.6637\n",
      "Epoch 144/150\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1279 - accuracy: 0.9464\n",
      "Epoch 144: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1279 - accuracy: 0.9464 - val_loss: 1.4005 - val_accuracy: 0.6726\n",
      "Epoch 145/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1607 - accuracy: 0.9688\n",
      "Epoch 145: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1721 - accuracy: 0.9308 - val_loss: 1.4006 - val_accuracy: 0.6991\n",
      "Epoch 146/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1557 - accuracy: 0.9688\n",
      "Epoch 146: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2474 - accuracy: 0.9085 - val_loss: 1.0766 - val_accuracy: 0.6814\n",
      "Epoch 147/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2727 - accuracy: 0.8750\n",
      "Epoch 147: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1708 - accuracy: 0.9375 - val_loss: 1.1790 - val_accuracy: 0.6726\n",
      "Epoch 148/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1147 - accuracy: 0.9688\n",
      "Epoch 148: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1259 - accuracy: 0.9576 - val_loss: 1.2137 - val_accuracy: 0.6726\n",
      "Epoch 149/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0970 - accuracy: 0.9375\n",
      "Epoch 149: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1319 - accuracy: 0.9442 - val_loss: 1.2407 - val_accuracy: 0.6637\n",
      "Epoch 150/150\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1373 - accuracy: 0.9375\n",
      "Epoch 150: val_loss did not improve from 0.59855\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1130 - accuracy: 0.9487 - val_loss: 1.4141 - val_accuracy: 0.6814\n",
      "Training completed in time:  0:00:16.875233\n"
     ]
    }
   ],
   "source": [
    "## Training my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "num_epochs=150\n",
    "num_batch_size=32\n",
    "\n",
    "checkpointer=ModelCheckpoint(filepath='/audio_classification.hdf5', verbose=1, save_best_only=True)\n",
    "start=datetime.now()\n",
    "\n",
    "model.fit(x_train,y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test,y_test), callbacks=[checkpointer])\n",
    "duration=datetime.now()-start\n",
    "\n",
    "print(\"Training completed in time: \",duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcc371d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6814159154891968\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(x_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a365e205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48944a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.66414881e-01, 2.33585119e-01],\n",
       "       [2.44138297e-04, 9.99755919e-01],\n",
       "       [8.16501852e-05, 9.99918342e-01],\n",
       "       [9.90994751e-01, 9.00530629e-03],\n",
       "       [9.96549964e-01, 3.44999041e-03],\n",
       "       [7.47256935e-01, 2.52743006e-01],\n",
       "       [6.42623831e-07, 9.99999404e-01],\n",
       "       [9.62184489e-01, 3.78155373e-02],\n",
       "       [9.99999523e-01, 4.46736721e-07],\n",
       "       [1.00000000e+00, 2.19152803e-08],\n",
       "       [9.46994603e-01, 5.30054420e-02],\n",
       "       [5.82773425e-03, 9.94172275e-01],\n",
       "       [1.63138136e-02, 9.83686149e-01],\n",
       "       [9.98792648e-01, 1.20732212e-03],\n",
       "       [2.04502430e-04, 9.99795496e-01],\n",
       "       [9.99999881e-01, 1.21730139e-07],\n",
       "       [2.10654318e-01, 7.89345682e-01],\n",
       "       [9.99713957e-01, 2.86065915e-04],\n",
       "       [9.99975324e-01, 2.46846939e-05],\n",
       "       [9.99861479e-01, 1.38469011e-04],\n",
       "       [2.95281779e-07, 9.99999762e-01],\n",
       "       [9.80574489e-01, 1.94254462e-02],\n",
       "       [2.71078795e-01, 7.28921175e-01],\n",
       "       [7.09911510e-02, 9.29008842e-01],\n",
       "       [3.92623633e-01, 6.07376397e-01],\n",
       "       [3.00329745e-01, 6.99670196e-01],\n",
       "       [4.09488566e-03, 9.95905042e-01],\n",
       "       [3.75391215e-01, 6.24608755e-01],\n",
       "       [4.55221161e-05, 9.99954462e-01],\n",
       "       [2.69486550e-02, 9.73051429e-01],\n",
       "       [9.72567976e-01, 2.74319779e-02],\n",
       "       [8.80443335e-01, 1.19556651e-01],\n",
       "       [9.84426677e-01, 1.55733293e-02],\n",
       "       [5.78072900e-03, 9.94219303e-01],\n",
       "       [3.11348975e-01, 6.88651025e-01],\n",
       "       [8.83351207e-01, 1.16648771e-01],\n",
       "       [1.89179957e-13, 1.00000000e+00],\n",
       "       [1.69028878e-01, 8.30971122e-01],\n",
       "       [5.18270885e-04, 9.99481738e-01],\n",
       "       [6.84682334e-07, 9.99999285e-01],\n",
       "       [9.82482910e-01, 1.75171234e-02],\n",
       "       [7.35032326e-03, 9.92649615e-01],\n",
       "       [9.23880219e-01, 7.61197358e-02],\n",
       "       [9.88208473e-01, 1.17915031e-02],\n",
       "       [1.99659485e-02, 9.80033994e-01],\n",
       "       [9.92035806e-01, 7.96421710e-03],\n",
       "       [4.80779272e-05, 9.99951959e-01],\n",
       "       [3.46405341e-06, 9.99996543e-01],\n",
       "       [9.82364595e-01, 1.76354237e-02],\n",
       "       [7.74816930e-01, 2.25183144e-01],\n",
       "       [4.34403345e-02, 9.56559598e-01],\n",
       "       [1.69619024e-01, 8.30380976e-01],\n",
       "       [8.07060860e-04, 9.99192894e-01],\n",
       "       [4.91405576e-01, 5.08594453e-01],\n",
       "       [1.09176636e-01, 8.90823305e-01],\n",
       "       [7.50579536e-01, 2.49420464e-01],\n",
       "       [2.47148710e-04, 9.99752820e-01],\n",
       "       [5.74827790e-01, 4.25172180e-01],\n",
       "       [2.49064341e-02, 9.75093544e-01],\n",
       "       [9.46246207e-01, 5.37537709e-02],\n",
       "       [4.82886195e-01, 5.17113805e-01],\n",
       "       [9.99909401e-01, 9.06475398e-05],\n",
       "       [9.97480929e-01, 2.51904968e-03],\n",
       "       [1.27672568e-01, 8.72327447e-01],\n",
       "       [9.99727786e-01, 2.72245990e-04],\n",
       "       [9.21904564e-01, 7.80954286e-02],\n",
       "       [9.97413874e-01, 2.58608675e-03],\n",
       "       [4.87332463e-01, 5.12667537e-01],\n",
       "       [9.38349485e-01, 6.16505332e-02],\n",
       "       [3.10727835e-01, 6.89272106e-01],\n",
       "       [3.48722003e-02, 9.65127766e-01],\n",
       "       [8.30954611e-01, 1.69045448e-01],\n",
       "       [5.95904179e-02, 9.40409601e-01],\n",
       "       [9.37182903e-01, 6.28170520e-02],\n",
       "       [6.17359996e-01, 3.82640004e-01],\n",
       "       [2.19256639e-01, 7.80743361e-01],\n",
       "       [6.66377008e-01, 3.33623081e-01],\n",
       "       [1.47886516e-03, 9.98521149e-01],\n",
       "       [9.39218044e-01, 6.07819483e-02],\n",
       "       [7.66263306e-01, 2.33736619e-01],\n",
       "       [3.77669781e-02, 9.62233007e-01],\n",
       "       [2.26059571e-01, 7.73940444e-01],\n",
       "       [9.99996305e-01, 3.67468988e-06],\n",
       "       [9.99996305e-01, 3.70125827e-06],\n",
       "       [9.34986055e-01, 6.50139526e-02],\n",
       "       [9.99123275e-01, 8.76765058e-04],\n",
       "       [3.16227926e-03, 9.96837735e-01],\n",
       "       [3.56222416e-04, 9.99643803e-01],\n",
       "       [9.88196790e-01, 1.18031548e-02],\n",
       "       [9.98034060e-01, 1.96588854e-03],\n",
       "       [7.43695199e-01, 2.56304771e-01],\n",
       "       [1.96351788e-08, 1.00000000e+00],\n",
       "       [9.99999881e-01, 6.30306189e-08],\n",
       "       [2.74544116e-03, 9.97254550e-01],\n",
       "       [9.42350388e-01, 5.76495938e-02],\n",
       "       [4.89187315e-02, 9.51081276e-01],\n",
       "       [9.24473405e-01, 7.55266249e-02],\n",
       "       [1.87203474e-02, 9.81279612e-01],\n",
       "       [2.24433735e-01, 7.75566220e-01],\n",
       "       [3.09474409e-01, 6.90525591e-01],\n",
       "       [9.99595582e-01, 4.04473045e-04],\n",
       "       [8.54986906e-02, 9.14501309e-01],\n",
       "       [7.53641416e-08, 9.99999881e-01],\n",
       "       [5.85757077e-01, 4.14242953e-01],\n",
       "       [9.57200766e-01, 4.27991748e-02],\n",
       "       [9.99559581e-01, 4.40404285e-04],\n",
       "       [4.21311506e-06, 9.99995828e-01],\n",
       "       [6.93617702e-01, 3.06382328e-01],\n",
       "       [6.65815413e-01, 3.34184557e-01],\n",
       "       [9.94376063e-01, 5.62399533e-03],\n",
       "       [9.99710143e-01, 2.89874384e-04],\n",
       "       [2.46640574e-02, 9.75335956e-01],\n",
       "       [9.99997616e-01, 2.35065636e-06]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b239d614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d14d743f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "#compute confusion matrix\n",
    "conf_matrix = confusion_matrix(np.argmax(y_test, axis=1), y_pred_classes)\n",
    "\n",
    "#Plot confusion matrix\n",
    "sns.heatmap( conf_matrix, annot=True, fmt='d', cmap= 'Blues')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d00d66",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a87feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Male_Female_Healthy_Dataset/1004-a_n.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "334d7154",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(features_extraction(filename)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe4b49fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-149.225266</td>\n",
       "      <td>174.276077</td>\n",
       "      <td>-18.307064</td>\n",
       "      <td>10.403212</td>\n",
       "      <td>-66.140961</td>\n",
       "      <td>-11.231764</td>\n",
       "      <td>-8.218404</td>\n",
       "      <td>-4.863341</td>\n",
       "      <td>-25.08256</td>\n",
       "      <td>-1.205913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736559</td>\n",
       "      <td>-0.999705</td>\n",
       "      <td>-1.608087</td>\n",
       "      <td>-2.276558</td>\n",
       "      <td>0.696951</td>\n",
       "      <td>-0.647705</td>\n",
       "      <td>0.926778</td>\n",
       "      <td>-2.020046</td>\n",
       "      <td>-1.749156</td>\n",
       "      <td>-0.680004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1          2          3          4          5   \\\n",
       "0 -149.225266  174.276077 -18.307064  10.403212 -66.140961 -11.231764   \n",
       "\n",
       "         6         7         8         9   ...        70        71        72  \\\n",
       "0 -8.218404 -4.863341 -25.08256 -1.205913  ...  0.736559 -0.999705 -1.608087   \n",
       "\n",
       "         73        74        75        76        77        78        79  \n",
       "0 -2.276558  0.696951 -0.647705  0.926778 -2.020046 -1.749156 -0.680004  \n",
       "\n",
       "[1 rows x 80 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7cc1950",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(feature_df.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e27f65b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 80)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "516b73f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.7233279e-04, 9.9982762e-01]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
